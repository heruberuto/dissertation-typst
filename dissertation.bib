@inproceedings{fever,
  author    = {Thorne, James and Vlachos, Andreas and Christodoulopoulos, Christos and Mittal, Arpit},
  title     = {{FEVER}: a Large-scale Dataset for Fact Extraction and {VERification}},
  booktitle = {NAACL-HLT},
  year      = {2018}
}

@inproceedings{fever1,
  author    = {Thorne, James and Vlachos, Andreas and Cocarascu, Oana and Christodoulopoulos, Christos and Mittal, Arpit},
  title     = {The {Fact Extraction and VERification (FEVER)} Shared Task},
  booktitle = {Proceedings of the First Workshop on {Fact Extraction and VERification (FEVER)}},
  year      = {2018}
}

@article{BARUA2020100119,
  title    = {Effects of misinformation on COVID-19 individual responses and recommendations for resilience of disastrous consequences of misinformation},
  journal  = {Progress in Disaster Science},
  volume   = {8},
  pages    = {100119},
  year     = {2020},
  issn     = {2590-0617},
  doi      = {https://doi.org/10.1016/j.pdisas.2020.100119},
  url      = {https://www.sciencedirect.com/science/article/pii/S2590061720300569},
  author   = {Zapan Barua and Sajib Barua and Salma Aktar and Najma Kabir and Mingze Li},
  keywords = {Coronavirus, Misinformation, Credibility evaluation, Social media, COVID-19 individual response},
  abstract = {The proliferation of misinformation on social media platforms is faster than the spread of Corona Virus Diseases (COVID-19) and it can generate hefty deleterious consequences on health amid a disaster like COVID-19. Drawing upon research on the stimulus-response theory (hypodermic needle theory) and the resilience theory, this study tested a conceptual framework considering general misinformation belief, conspiracy belief, and religious misinformation belief as the stimulus; and credibility evaluations as resilience strategy; and their effects on COVID-19 individual responses. Using a self-administered online survey during the COVID-19 pandemic, the study obtained 483 useable responses and after test, finds that all-inclusive, the propagation of misinformation on social media undermines the COVID-19 individual responses. Particularly, credibility evaluation of misinformation strongly predicts the COVID-19 individual responses with positive influences and religious misinformation beliefs as well as conspiracy beliefs and general misinformation beliefs come next and influence negatively. The findings and general recommendations will help the public, in general, to be cautious about misinformation, and the respective authority of a country, in particular, for initiating proper safety measures about disastrous misinformation to protect the public health from being exploited.}
}

@misc{stem,
  author       = {{\textsf{STEM}}},
  year         = {2021},
  title        = {Mýtům a konspiracím o COVID-19 věří více než třetina české internetové populace | Stem.cz},
  howpublished = {\url{https://www.stem.cz/mytum-a-konspiracim-o-covid-19-veri-vice-nez-tretina-ceske-internetove-populace/}},
  note         = {Accessed: 2021-05-03}
}

@misc{moat,
  author       = {Dylan Patel and Aftzal Ahmad},
  year         = {2023},
  title        = {Google "We Have No Moat, And Neither Does OpenAI"},
  howpublished = {\url{https://www.semianalysis.com/p/google-we-have-no-moat-and-neither}},
  note         = {Accessed: 2023-09-06}
}

@misc{nlpprogress,
  author       = {\textsf{NLP-Progress}},
  year         = {2023},
  title        = {On Summarization},
  howpublished = {\url{http://nlpprogress.com/english/summarization.html}},
  note         = {Accessed: 2023-09-06}
}

@misc{fncweb,
  author       = {Dean Pomerlau and Delip Rao},
  year         = {2017},
  title        = {Fake News Challenge: Exploring how artificial intelligence technologies could be leveraged to combat fake news},
  howpublished = {\url{http://www.fakenewschallenge.org}},
  note         = {Accessed: 2023-09-06}
}

@misc{vicuna,
  author       = {Vicuna},
  year         = {2023},
  title        = {Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  howpublished = {\url{https://vicuna.lmsys.org/}},
  note         = {Accessed: 2023-09-04}
}

@misc{alpaca,
  author       = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto},
  year         = {2023},
  title        = {Alpaca: A Strong, Replicable Instruction-Following Model},
  howpublished = {\url{https://crfm.stanford.edu/2023/03/13/alpaca.html}},
  note         = {Accessed: 2023-09-04}
}

@misc{mediawiki,
  author       = {Yuri Astrakhan    and Roan Kattouw      and Victor Vasiliev   and Bryan Tong Minhand Sam Reed          and Brad Jorsch},
  year         = {2021},
  title        = {API: Main Page},
  howpublished = {\url{mediawiki.org/wiki/API:Main_page}},
  note         = {Accessed: 2021-05-11}
}

@misc{fever2adversarial,
  title         = {Adversarial attacks against {Fact Extraction and VERification}},
  author        = {James Thorne and Andreas Vlachos},
  year          = {2019},
  eprint        = {1903.05543},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{infobert,
  author        = {Boxin Wang and
                   Shuohang Wang and
                   Yu Cheng and
                   Zhe Gan and
                   Ruoxi Jia and
                   Bo Li and
                   Jingjing Liu},
  title         = {InfoBERT: Improving Robustness of Language Models from An Information
                   Theoretic Perspective},
  journal       = {CoRR},
  volume        = {abs/2010.02329},
  year          = {2020},
  url           = {https://arxiv.org/abs/2010.02329},
  archiveprefix = {arXiv},
  eprint        = {2010.02329},
  timestamp     = {Wed, 18 Nov 2020 16:11:01 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2010-02329.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@misc{dedkova,
  title  = {Multi-stage Methods for Document Retrieval in the Czech Language},
  author = {Dědková, Barbora},
  year   = {2021}
}

@misc{butora,
  title        = {Crowd-sourcing Platform Frontend for Fact-checking},
  howpublished = {\url{https://dspace.cvut.cz/handle/10467/109505}},
  author       = {Bútora, Roman},
  year         = {2023}
}

@misc{diplomka,
  title        = {Dataset for Automated Fact Checking in Czech Language},
  howpublished = {\url{https://dspace.cvut.cz/handle/10467/95430}},
  author       = {Ullrich, Herbert},
  year         = {2021}
}

@misc{mlynar,
  title        = {Automated Fact Checking Based on Czech Wikipedia},
  howpublished = {\url{https://dspace.cvut.cz/handle/10467/109219}},
  author       = {Mlynář, Tomáš},
  year         = {2023}
}

@misc{krotil,
  title        = {Text Summarization Methods in Czech},
  howpublished = {\url{https://dspace.cvut.cz/handle/10467/101028}},
  author       = {Krotil, Marian},
  year         = {2022}
}

@misc{korladinova,
  title        = {Extracting Keywords from Textual Data Clusters},
  howpublished = {\url{https://dspace.cvut.cz/handle/10467/109209}},
  author       = {Korladinova, Diana},
  year         = {2023}
}

@misc{semin,
  title        = {Multitask Learning for NLP Classifiers},
  howpublished = {\url{https://dspace.cvut.cz/handle/10467/109243}},
  author       = {Semin, Danil},
  year         = {2023}
}

@misc{rypar,
  title        = {Methods of Document Retrieval for Fact-Checking},
  author       = {Rýpar, Martin},
  year         = {2021},
  howpublished = {\url{https://www.overleaf.com/read/thbvcjvvvfjp}},
  note         = {[Online; accessed 21-May-2021]}
}

@misc{deepset,
  title        = {deepset - Cutting-edge NLP Solutions},
  author       = {\textsf{deepset}},
  year         = {2021},
  howpublished = {\url{https://deepset.ai/}},
  note         = {[Online; accessed 21-May-2021]}
}

@misc{deeppavlov,
  title        = {DeepPavlov: an open source conversational AI framework},
  author       = {\textsf{DeepPavlov}},
  year         = {2021},
  howpublished = {\url{https://deeppavlov.ai/}},
  note         = {[Online; accessed 21-May-2021]}
}

@misc{gazo,
  title  = {Algorithms for Document Retrieval in Czech Language Supporting Long Inputs},
  author = {Gažo, Alexander},
  year   = {2021}
}

@web{danish,
  title        = {Danish Fact Verification:
                  An End-to-End Machine Learning System for
                  Automatic Fact-Checking of Danish Textual Claims},
  author       = {Binau, Julie and Schulte, Henri},
  year         = {2020},
  howpublished = {\url{https://www.derczynski.com/itu/docs/fever-da_jubi_hens.pdf}}
}

@misc{czert,
  title         = {Czert -- Czech BERT-like Model for Language Representation},
  author        = {Jakub Sido and Ondřej Pražák and Pavel Přibáň and Jan Pašek and Michal Seják and Miloslav Konopík},
  year          = {2021},
  eprint        = {2103.13031},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{fever2,
  title     = {The {FEVER}2.0 Shared Task},
  author    = {Thorne, James  and
               Vlachos, Andreas  and
               Cocarascu, Oana  and
               Christodoulopoulos, Christos  and
               Mittal, Arpit},
  booktitle = {Proceedings of the Second Workshop on Fact Extraction and VERification (FEVER)},
  month     = nov,
  year      = {2019},
  address   = {Hong Kong, China},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/D19-6601},
  doi       = {10.18653/v1/D19-6601},
  pages     = {1--6},
  abstract  = {We present the results of the second Fact Extraction and VERification (FEVER2.0) Shared Task. The task challenged participants to both build systems to verify factoid claims using evidence retrieved from Wikipedia and to generate adversarial attacks against other participant’s systems. The shared task had three phases: \textit{building, breaking and fixing}. There were 8 systems in the builder’s round, three of which were new qualifying submissions for this shared task, and 5 adversaries generated instances designed to induce classification errors and one builder submitted a fixed system which had higher FEVER score and resilience than their first submission. All but one newly submitted systems attained FEVER scores higher than the best performing system from the first shared task and under adversarial evaluation, all systems exhibited losses in FEVER score. There was a great variety in adversarial attack types as well as the techniques used to generate the attacks, In this paper, we present the results of the shared task and a summary of the systems, highlighting commonalities and innovations among participating systems.}
}

@inproceedings{nie2019combining,
  title     = {Combining Fact Extraction and Verification with Neural Semantic Matching Networks},
  author    = {Yixin Nie and Haonan Chen and Mohit Bansal},
  booktitle = {Association for the Advancement of Artificial Intelligence ({AAAI})},
  year      = {2019}
}

@inproceedings{papelo,
  title     = {Team Papelo: Transformer Networks at FEVER},
  author    = {Christopher Malon},
  booktitle = {Proceedings of the EMNLP First Workshop on Fact Extraction and Verification},
  year      = {2018}
}

@article{athene,
  title   = {UKP-Athene: Multi-Sentence Textual Entailment for Claim Verification},
  author  = {Hanselowski, Andreas and Zhang, Hao and Li, Zile and Sorokin, Daniil and Schiller, Benjamin and Schulz, Claudia and Gurevych, Iryna},
  journal = {arXiv preprint arXiv:1809.01479},
  year    = {2018}
}

@inproceedings{yoneda-etal-2018-ucl,
  title     = {{UCL} Machine Reading Group: Four Factor Framework For Fact Finding ({H}exa{F})},
  author    = {Yoneda, Takuma  and
               Mitchell, Jeff  and
               Welbl, Johannes  and
               Stenetorp, Pontus  and
               Riedel, Sebastian},
  booktitle = {Proceedings of the First Workshop on Fact Extraction and {VER}ification ({FEVER})},
  month     = nov,
  year      = {2018},
  address   = {Brussels, Belgium},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/W18-5515},
  doi       = {10.18653/v1/W18-5515},
  pages     = {97--102},
  abstract  = {In this paper we describe our 2nd place FEVER shared-task system that achieved a FEVER score of 62.52{\%} on the provisional test set (without additional human evaluation), and 65.41{\%} on the development set. Our system is a four stage model consisting of document retrieval, sentence retrieval, natural language inference and aggregation. Retrieval is performed leveraging task-specific features, and then a natural language inference model takes each of the retrieved sentences paired with the claimed fact. The resulting predictions are aggregated across retrieved sentences with a Multi-Layer Perceptron, and re-ranked corresponding to the final prediction.}
}

@article{drqa,
  author        = {Danqi Chen and
                   Adam Fisch and
                   Jason Weston and
                   Antoine Bordes},
  title         = {Reading Wikipedia to Answer Open-Domain Questions},
  journal       = {CoRR},
  volume        = {abs/1704.00051},
  year          = {2017},
  url           = {http://arxiv.org/abs/1704.00051},
  archiveprefix = {arXiv},
  eprint        = {1704.00051},
  timestamp     = {Mon, 13 Aug 2018 16:47:17 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/ChenFWB17.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{Lazer1094,
  author    = {Lazer, David M. J. and Baum, Matthew A. and Benkler, Yochai and Berinsky, Adam J. and Greenhill, Kelly M. and Menczer, Filippo and Metzger, Miriam J. and Nyhan, Brendan and Pennycook, Gordon and Rothschild, David and Schudson, Michael and Sloman, Steven A. and Sunstein, Cass R. and Thorson, Emily A. and Watts, Duncan J. and Zittrain, Jonathan L.},
  title     = {The science of fake news},
  volume    = {359},
  number    = {6380},
  pages     = {1094--1096},
  year      = {2018},
  doi       = {10.1126/science.aao2998},
  publisher = {American Association for the Advancement of Science},
  issn      = {0036-8075},
  url       = {https://science.sciencemag.org/content/359/6380/1094},
  eprint    = {https://science.sciencemag.org/content/359/6380/1094.full.pdf},
  journal   = {Science}
}

@article{embed,
  author        = {Luk{\'{a}}s Svoboda and
                   Tom{\'{a}}s Brychc{\'{\i}}n},
  title         = {New word analogy corpus for exploring embeddings of Czech words},
  journal       = {CoRR},
  volume        = {abs/1608.00789},
  year          = {2016},
  url           = {http://arxiv.org/abs/1608.00789},
  archiveprefix = {arXiv},
  eprint        = {1608.00789},
  timestamp     = {Mon, 13 Aug 2018 16:47:04 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/SvobodaB16.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deseption,
  title     = {{D}e{S}e{P}tion: Dual Sequence Prediction and Adversarial Examples for Improved Fact-Checking},
  author    = {Hidey, Christopher  and
               Chakrabarty, Tuhin  and
               Alhindi, Tariq  and
               Varia, Siddharth  and
               Krstovski, Kriste  and
               Diab, Mona  and
               Muresan, Smaranda},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/2020.acl-main.761},
  doi       = {10.18653/v1/2020.acl-main.761},
  pages     = {8593--8606},
  abstract  = {The increased focus on misinformation has spurred development of data and systems for detecting the veracity of a claim as well as retrieving authoritative evidence. The Fact Extraction and VERification (FEVER) dataset provides such a resource for evaluating endto- end fact-checking, requiring retrieval of evidence from Wikipedia to validate a veracity prediction. We show that current systems for FEVER are vulnerable to three categories of realistic challenges for fact-checking {--} multiple propositions, temporal reasoning, and ambiguity and lexical variation {--} and introduce a resource with these types of claims. Then we present a system designed to be resilient to these “attacks” using multiple pointer networks for document selection and jointly modeling a sequence of evidence sentences and veracity relation predictions. We find that in handling these attacks we obtain state-of-the-art results on FEVER, largely due to improved evidence retrieval.}
}

@inproceedings{snli:emnlp2015,
  author    = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher and Manning, Christopher D.},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  publisher = {Association for Computational Linguistics},
  title     = {A large annotated corpus for learning natural language inference},
  year      = {2015}
}

@article{anli,
  author        = {Yixin Nie and
                   Adina Williams and
                   Emily Dinan and
                   Mohit Bansal and
                   Jason Weston and
                   Douwe Kiela},
  title         = {Adversarial {NLI:} {A} New Benchmark for Natural Language Understanding},
  journal       = {CoRR},
  volume        = {abs/1910.14599},
  year          = {2019},
  url           = {http://arxiv.org/abs/1910.14599},
  archiveprefix = {arXiv},
  eprint        = {1910.14599},
  timestamp     = {Mon, 04 Nov 2019 09:10:30 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1910-14599.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{multinli,
  author    = {Williams, Adina
               and Nangia, Nikita
               and Bowman, Samuel},
  title     = {A Broad-Coverage Challenge Corpus for 
               Sentence Understanding through Inference},
  booktitle = {Proceedings of the 2018 Conference of 
               the North American Chapter of the 
               Association for Computational Linguistics:
               Human Language Technologies, Volume 1 (Long
               Papers)},
  year      = {2018},
  publisher = {Association for Computational Linguistics},
  pages     = {1112--1122},
  location  = {New Orleans, Louisiana},
  url       = {http://aclweb.org/anthology/N18-1101}
}

@misc{wang2021entailment,
  title         = {Entailment as Few-Shot Learner},
  author        = {Sinong Wang and Han Fang and Madian Khabsa and Hanzi Mao and Hao Ma},
  year          = {2021},
  eprint        = {2104.14690},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{roberta,
  author        = {Yinhan Liu and
                   Myle Ott and
                   Naman Goyal and
                   Jingfei Du and
                   Mandar Joshi and
                   Danqi Chen and
                   Omer Levy and
                   Mike Lewis and
                   Luke Zettlemoyer and
                   Veselin Stoyanov},
  title         = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal       = {CoRR},
  volume        = {abs/1907.11692},
  year          = {2019},
  url           = {http://arxiv.org/abs/1907.11692},
  archiveprefix = {arXiv},
  eprint        = {1907.11692},
  timestamp     = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{xlm-roberta,
  author        = {Alexis Conneau and
                   Kartikay Khandelwal and
                   Naman Goyal and
                   Vishrav Chaudhary and
                   Guillaume Wenzek and
                   Francisco Guzm{\'{a}}n and
                   Edouard Grave and
                   Myle Ott and
                   Luke Zettlemoyer and
                   Veselin Stoyanov},
  title         = {Unsupervised Cross-lingual Representation Learning at Scale},
  journal       = {CoRR},
  volume        = {abs/1911.02116},
  year          = {2019},
  url           = {http://arxiv.org/abs/1911.02116},
  archiveprefix = {arXiv},
  eprint        = {1911.02116},
  timestamp     = {Mon, 11 Nov 2019 18:38:09 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1911-02116.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@techreport{unicode,
  author          = {Ken Whistler},
  title           = {UNICODE NORMALIZATION FORMS},
  type            = {Unicode Standard Annex},
  number          = {15},
  institution     = {Unicode Consortium},
  address         = {Mountain View, CA},
  day             = {24},
  month           = feb,
  year            = {2020},
  bibdate         = {2021-05-09},
  bibsource       = {http://www.math.utah.edu/pub/tex/bib/unicode.bib},
  url             = {http://www.unicode.org/reports/tr15/},
  abstract        = {This annex describes normalization forms for Unicode text. When implementations keep strings in a normalized form, they can be assured that equivalent strings have a unique binary representation. This annex also provides examples, additional specifications regarding normalization of Unicode text, and information about conformance testing for Unicode normalization forms.},}

@misc{lindat,
  title     = {{LINDAT} Translation service},
  author    = {Ko{\v s}arko, Ond{\v r}ej and Vari{\v s}, Du{\v s}an and Popel, Martin},
  url       = {http://hdl.handle.net/11234/1-2922},
  note      = {{LINDAT}/{CLARIAH}-{CZ} digital library at the Institute of Formal and Applied Linguistics ({{\'U}FAL}), Faculty of Mathematics and Physics, Charles University},
  copyright = {{BSD} 2-Clause "Simplified" or "{FreeBSD}" license},
  year      = {2019}
}

@misc{wiki:reliable,
  author       = {\textsf{Wikipedia}},
  title        = {{Wikipedia:Wikipedia is not a reliable source} --- {W}ikipedia{,} The Free Encyclopedia},
  year         = {2021},
  howpublished = {\url{http://en.wikipedia.org/w/index.php?title=Wikipedia\%3AWikipedia\%20is\%20not\%20a\%20reliable\%20source&oldid=1017600260}},
  note         = {[Online; accessed 12-May-2021]}
}

@misc{wiki:style,
  author       = {\textsf{Wikipedia}},
  title        = {{Wikipedia:Encyclopedic style} --- {W}ikipedia{,} The Free Encyclopedia},
  year         = {2021},
  howpublished = {\url{https://en.wikipedia.org/w/index.php?title=Wikipedia:Encyclopedic_style&oldid=1009871271}},
  note         = {[Online; accessed 12-May-2021]}
}

@inproceedings{overview,
  title     = {An overview of Natural Language Inference Data Collection: The way forward?},
  author    = {Chatzikyriakidis, Stergios  and
               Cooper, Robin  and
               Dobnik, Simon  and
               Larsson, Staffan},
  booktitle = {Proceedings of the Computing Natural Language Inference Workshop},
  year      = {2017},
  url       = {https://www.aclweb.org/anthology/W17-7203},
  pages     = {2}
}

@misc{drawsql,
  author       = {\texttt{\textbf{draw}SQL}},
  title        = {fcheck | DrawSQL},
  year         = {2021},
  howpublished = {\url{https://drawsql.app/sir/diagrams/fcheck}},
  note         = {[Online; accessed 12-May-2021]}
}

@misc{ects,
  author       = {{The European Commission}},
  title        = {ECTS users' guide 2015},
  year         = {2015},
  howpublished = {\url{https://op.europa.eu/en/publication-detail/-/publication/da7467e6-8450-11e5-b8b7-01aa75ed71a1}},
  note         = {[Online; accessed 12-May-2021]}
}

@misc{honza,
  author       = {Jan Drchal},
  title        = {Anotace dat pro ověřování faktů nad databází článků ČTK},
  year         = {2020},
  howpublished = {\url{https://fcheck.fel.cvut.cz/2020_fcheck_anotace.pdf}},
  note         = {[Online; accessed 13-May-2021]}
}

@misc{yii,
  author       = {\textsf{{Yii}}},
  title        = {Yii PHP Framework},
  year         = {2021},
  howpublished = {\url{https://www.yiiframework.com/}},
  note         = {[Online; accessed 12-May-2021]}
}

@misc{michal,
  author       = {Michal Pitr},
  title        = {\textsf{CTU FEE GitLab} -- {Experimental}: Michal~{Pitr}},
  year         = {2020},
  howpublished = {\url{https://gitlab.fel.cvut.cz/factchecking/experimental-michal_pitr}},
  note         = {[Online; accessed 14-May-2021]}
}

@misc{honzagit,
  author       = {Jan Drchal and Herbert Ullrich},
  title        = {\textsf{CTU FEE GitLab} -- {Fact} {Checking} {Experimental} ({Honza} {Drchal})},
  year         = {2020},
  howpublished = {\url{https://gitlab.fel.cvut.cz/factchecking/drchajan}},
  note         = {[Online; accessed 14-May-2021]}
}

@inproceedings{requirements,
  author    = {Nuseibeh, Bashar and Easterbrook, Steve},
  title     = {Requirements Engineering: A Roadmap},
  year      = {2000},
  isbn      = {1581132530},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/336512.336523},
  doi       = {10.1145/336512.336523},
  booktitle = {Proceedings of the Conference on The Future of Software Engineering},
  pages     = {35–46},
  numpages  = {12},
  location  = {Limerick, Ireland},
  series    = {ICSE '00}
}

@article{10.1145/320434.320440,
  author     = {Chen, Peter Pin-Shan},
  title      = {The Entity-Relationship Model—toward a Unified View of Data},
  year       = {1976},
  issue_date = {March 1976},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {1},
  number     = {1},
  issn       = {0362-5915},
  url        = {https://doi.org/10.1145/320434.320440},
  doi        = {10.1145/320434.320440},
  abstract   = {A data model, called the entity-relationship model, is proposed. This model incorporates some of the important semantic information about the real world. A special diagrammatic technique is introduced as a tool for database design. An example of database design and description using the model and the diagrammatic technique is given. Some implications for data integrity, information retrieval, and data manipulation are discussed.The entity-relationship model can be used as a basis for unification of different views of data: the network model, the relational model, and the entity set model. Semantic ambiguities in these models are analyzed. Possible ways to derive their views of data from the entity-relationship model are presented.},
  journal    = {ACM Trans. Database Syst.},
  month      = mar,
  pages      = {9–36},
  numpages   = {28},
  keywords   = {network model, semantics of data, data integrity and consistency, data models, logigcal view of data, Data Base Task Group, database design, entity set model, relational model, data definition and manipulation, entity-relationship model}
}

@inproceedings{bm25,
  author    = {Robertson, Stephen and Walker, S. and Jones, S. and Hancock-Beaulieu, M. M. and Gatford, M.},
  title     = {Okapi at TREC-3},
  booktitle = {Overview of the Third Text REtrieval Conference (TREC-3)},
  year      = {1995},
  month     = {January}
}

@inproceedings{strakova-etal-2019-neural,
  title     = {Neural Architectures for Nested {NER} through Linearization},
  author    = {Strakov{\'a}, Jana  and
               Straka, Milan  and
               Hajic, Jan},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/P19-1527},
  doi       = {10.18653/v1/P19-1527},
  pages     = {5326--5331},
  abstract  = {We propose two neural network architectures for nested named entity recognition (NER), a setting in which named entities may overlap and also be labeled with more than one label. We encode the nested labels using a linearized scheme. In our first proposed approach, the nested labels are modeled as multilabels corresponding to the Cartesian product of the nested labels in a standard LSTM-CRF architecture. In the second one, the nested NER is viewed as a sequence-to-sequence problem, in which the input sequence consists of the tokens and output sequence of the labels, using hard attention on the word whose label is being predicted. The proposed methods outperform the nested NER state of the art on four corpora: ACE-2004, ACE-2005, GENIA and Czech CNEC. We also enrich our architectures with the recently published contextual embeddings: ELMo, BERT and Flair, reaching further improvements for the four nested entity corpora. In addition, we report flat NER state-of-the-art results for CoNLL-2002 Dutch and Spanish and for CoNLL-2003 English.}
}

@article{cohen,
  author  = {Jacob Cohen},
  title   = {A Coefficient of Agreement for Nominal Scales},
  journal = {Educational and Psychological Measurement},
  volume  = {20},
  number  = {1},
  pages   = {37-46},
  year    = {1960},
  doi     = {10.1177/001316446002000104},
  url     = { 
             https://doi.org/10.1177/001316446002000104
             
             },
  eprint  = { 
             https://doi.org/10.1177/001316446002000104
             
             }
}

@article{vaswani,
  author        = {Ashish Vaswani and
                   Noam Shazeer and
                   Niki Parmar and
                   Jakob Uszkoreit and
                   Llion Jones and
                   Aidan N. Gomez and
                   Lukasz Kaiser and
                   Illia Polosukhin},
  title         = {Attention Is All You Need},
  journal       = {CoRR},
  volume        = {abs/1706.03762},
  year          = {2017},
  url           = {http://arxiv.org/abs/1706.03762},
  archiveprefix = {arXiv},
  eprint        = {1706.03762},
  timestamp     = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{lstm,
  author        = {Jianpeng Cheng and
                   Li Dong and
                   Mirella Lapata},
  title         = {Long Short-Term Memory-Networks for Machine Reading},
  journal       = {CoRR},
  volume        = {abs/1601.06733},
  year          = {2016},
  url           = {http://arxiv.org/abs/1601.06733},
  archiveprefix = {arXiv},
  eprint        = {1601.06733},
  timestamp     = {Mon, 13 Aug 2018 16:48:39 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/ChengDL16.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{gpt3,
  author        = {Tom B. Brown and
                   Benjamin Mann and
                   Nick Ryder and
                   Melanie Subbiah and
                   Jared Kaplan and
                   Prafulla Dhariwal and
                   Arvind Neelakantan and
                   Pranav Shyam and
                   Girish Sastry and
                   Amanda Askell and
                   Sandhini Agarwal and
                   Ariel Herbert{-}Voss and
                   Gretchen Krueger and
                   Tom Henighan and
                   Rewon Child and
                   Aditya Ramesh and
                   Daniel M. Ziegler and
                   Jeffrey Wu and
                   Clemens Winter and
                   Christopher Hesse and
                   Mark Chen and
                   Eric Sigler and
                   Mateusz Litwin and
                   Scott Gray and
                   Benjamin Chess and
                   Jack Clark and
                   Christopher Berner and
                   Sam McCandlish and
                   Alec Radford and
                   Ilya Sutskever and
                   Dario Amodei},
  title         = {Language Models are Few-Shot Learners},
  journal       = {CoRR},
  volume        = {abs/2005.14165},
  year          = {2020},
  url           = {https://arxiv.org/abs/2005.14165},
  archiveprefix = {arXiv},
  eprint        = {2005.14165},
  timestamp     = {Wed, 03 Jun 2020 11:36:54 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{twotower,
  author        = {Wei{-}Cheng Chang and
                   Felix X. Yu and
                   Yin{-}Wen Chang and
                   Yiming Yang and
                   Sanjiv Kumar},
  title         = {Pre-training Tasks for Embedding-based Large-scale Retrieval},
  journal       = {CoRR},
  volume        = {abs/2002.03932},
  year          = {2020},
  url           = {https://arxiv.org/abs/2002.03932},
  archiveprefix = {arXiv},
  eprint        = {2002.03932},
  timestamp     = {Wed, 12 Feb 2020 16:38:55 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2002-03932.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{10.1257/jep.31.2.211,
  author  = {Allcott, Hunt and Gentzkow, Matthew},
  title   = {Social Media and Fake News in the 2016 Election},
  journal = {Journal of Economic Perspectives},
  volume  = {31},
  number  = {2},
  year    = {2017},
  month   = {May},
  pages   = {211-36},
  doi     = {10.1257/jep.31.2.211},
  url     = {https://www.aeaweb.org/articles?id=10.1257/jep.31.2.211}
}

@article{doi:10.1177/2056305119888654,
  author   = {Tom Buchanan and Vladlena Benson},
  title    = {Spreading Disinformation on Facebook: Do Trust in Message Source, Risk Propensity, or Personality Affect the Organic Reach of “Fake News”?},
  journal  = {Social Media + Society},
  volume   = {5},
  number   = {4},
  pages    = {2056305119888654},
  year     = {2019},
  doi      = {10.1177/2056305119888654},
  url      = { 
              https://doi.org/10.1177/2056305119888654
              
              },
  eprint   = { 
              https://doi.org/10.1177/2056305119888654
              
              },
  abstract = { There is considerable concern about the propagation of disinformation through social media, particularly for political purposes. “Organic reach” has been found to be important in the propagation of disinformation on social networks. This is the phenomenon whereby social media users extend the audience for a piece of information: interacting with it, or sharing it with their wider networks, greatly increases the number of people the information reaches. This project evaluated the extent to which characteristics of the message source (how trustworthy they were) and the recipient (risk propensity and personality) influenced the organic reach of a potentially false message. In an online study, 357 Facebook users completed personality and risk propensity scales and rated their likelihood of interacting in various ways with a message posted by either a trustworthy or untrustworthy source. Message source impacted on overall organic reach, with messages from trusted sources being more likely to be propagated. Risk propensity did not influence reach. However, low scores on trait agreeableness predicted greater likelihood of interacting with a message. The findings provide preliminary evidence that both message source and recipient characteristics can potentially influence the spread of disinformation. }
}

@inproceedings{shukai,
  author = {Shu, Kai and Wang, Suhang and Le, Thai and Lee, Dongwon and Liu, Huan},
  year   = {2018},
  month  = {08},
  pages  = {},
  title  = {Deep Headline Generation for Clickbait Detection},
  doi    = {10.1109/ICDM.2018.00062}
}

@book{jeffries2001extreme,
  title     = {Extreme Programming Installed},
  author    = {Jeffries, R. and Anderson, A. and Hendrickson, C.},
  isbn      = {9780201708424},
  lccn      = {00056928},
  series    = {XP series},
  url       = {https://books.google.cz/books?id=l4zO3OWkdIsC},
  year      = {2001},
  publisher = {Addison-Wesley}
}

@book{krippendorff2013content,
  title     = {Content Analysis: An Introduction to Its Methodology},
  author    = {Krippendorff, K.},
  isbn      = {9781412983150},
  lccn      = {2011048278},
  url       = {https://books.google.cz/books?id=s\_yqFXnGgjQC},
  year      = {2013},
  pages     = {221--250},
  publisher = {SAGE Publications}
}

@article{sentence-transformers,
  author        = {Nils Reimers and
                   Iryna Gurevych},
  title         = {Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  journal       = {CoRR},
  volume        = {abs/1908.10084},
  year          = {2019},
  url           = {http://arxiv.org/abs/1908.10084},
  archiveprefix = {arXiv},
  eprint        = {1908.10084},
  timestamp     = {Thu, 26 Nov 2020 12:13:54 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1908-10084.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{benchmarks,
  author        = {Shane Storks and
                   Qiaozi Gao and
                   Joyce Y. Chai},
  title         = {Commonsense Reasoning for Natural Language Understanding: {A} Survey
                   of Benchmarks, Resources, and Approaches},
  journal       = {CoRR},
  volume        = {abs/1904.01172},
  year          = {2019},
  url           = {http://arxiv.org/abs/1904.01172},
  archiveprefix = {arXiv},
  eprint        = {1904.01172},
  timestamp     = {Wed, 24 Apr 2019 12:21:25 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1904-01172.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{poliak,
  author        = {Adam Poliak},
  title         = {A Survey on Recognizing Textual Entailment as an {NLP} Evaluation},
  journal       = {CoRR},
  volume        = {abs/2010.03061},
  year          = {2020},
  url           = {https://arxiv.org/abs/2010.03061},
  archiveprefix = {arXiv},
  eprint        = {2010.03061},
  timestamp     = {Tue, 13 Oct 2020 15:25:23 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2010-03061.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{huggingface,
  author        = {Thomas Wolf and
                   Lysandre Debut and
                   Victor Sanh and
                   Julien Chaumond and
                   Clement Delangue and
                   Anthony Moi and
                   Pierric Cistac and
                   Tim Rault and
                   R{\'{e}}mi Louf and
                   Morgan Funtowicz and
                   Jamie Brew},
  title         = {HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  journal       = {CoRR},
  volume        = {abs/1910.03771},
  year          = {2019},
  url           = {http://arxiv.org/abs/1910.03771},
  archiveprefix = {arXiv},
  eprint        = {1910.03771},
  timestamp     = {Tue, 02 Jun 2020 12:49:01 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1910-03771.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{squad,
  author        = {Pranav Rajpurkar and
                   Jian Zhang and
                   Konstantin Lopyrev and
                   Percy Liang},
  title         = {SQuAD: 100, 000+ Questions for Machine Comprehension of Text},
  journal       = {CoRR},
  volume        = {abs/1606.05250},
  year          = {2016},
  url           = {http://arxiv.org/abs/1606.05250},
  archiveprefix = {arXiv},
  eprint        = {1606.05250},
  timestamp     = {Mon, 24 Aug 2020 14:01:25 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/RajpurkarZLL16.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{guo-etal-2022-survey,
  title     = {A Survey on Automated Fact-Checking},
  author    = {Guo, Zhijiang  and
               Schlichtkrull, Michael  and
               Vlachos, Andreas},
  journal   = {Transactions of the Association for Computational Linguistics},
  volume    = {10},
  year      = {2022},
  address   = {Cambridge, MA},
  publisher = {MIT Press},
  url       = {https://aclanthology.org/2022.tacl-1.11},
  doi       = {10.1162/tacl_a_00454},
  pages     = {178--206},
  abstract  = {Fact-checking has become increasingly important due to the speed with which both information and misinformation can spread in the modern media ecosystem. Therefore, researchers have been exploring how fact-checking can be automated, using techniques based on natural language processing, machine learning, knowledge representation, and databases to automatically predict the veracity of claims. In this paper, we survey automated fact-checking stemming from natural language processing, and discuss its connections to related tasks and disciplines. In this process, we present an overview of existing datasets and models, aiming to unify the various definitions given and identify common concepts. Finally, we highlight challenges for future research.}
}

@book{Aho:72,
  author    = {Alfred V. Aho and Jeffrey D. Ullman},
  title     = {The Theory of Parsing, Translation and Compiling},
  year      = {1972},
  volume    = {1},
  publisher = {Prentice-Hall},
  address   = {Englewood Cliffs, NJ}
}

@book{APA:83,
  author    = {{American Psychological Association}},
  title     = {Publications Manual},
  year      = {1983},
  publisher = {American Psychological Association},
  address   = {Washington, DC}
}

@article{Chandra:81,
  author  = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
  year    = {1981},
  title   = {Alternation},
  journal = {Journal of the Association for Computing Machinery},
  volume  = {28},
  number  = {1},
  pages   = {114--133},
  doi     = {10.1145/322234.322243}
}

@inproceedings{andrew2007scalable,
  title     = {Scalable training of {L1}-regularized log-linear models},
  author    = {Andrew, Galen and Gao, Jianfeng},
  booktitle = {Proceedings of the 24th International Conference on Machine Learning},
  pages     = {33--40},
  year      = {2007}
}

@book{Gusfield:97,
  author    = {Dan Gusfield},
  title     = {Algorithms on Strings, Trees and Sequences},
  year      = {1997},
  publisher = {Cambridge University Press},
  address   = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
  author  = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
  title   = {Yara Parser: {A} Fast and Accurate Dependency Parser},
  journal = {Computing Research Repository},
  volume  = {arXiv:1503.06733},
  year    = {2015},
  url     = {http://arxiv.org/abs/1503.06733},
  note    = {version 2}
}

@article{Ando2005,
  acmid      = {1194905},
  author     = {Ando, Rie Kubota and Zhang, Tong},
  issn       = {1532-4435},
  issue_date = {12/1/2005},
  journal    = {Journal of Machine Learning Research},
  month      = dec,
  numpages   = {37},
  pages      = {1817--1853},
  publisher  = {JMLR.org},
  title      = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
  volume     = {6},
  year       = {2005}
}

@inproceedings{bert-score,
  title     = {BERTScore: Evaluating Text Generation with BERT},
  author    = {Tianyi Zhang* and Varsha Kishore* and Felix Wu* and Kilian Q. Weinberger and Yoav Artzi},
  booktitle = {International Conference on Learning Representations},
  year      = {2020},
  url       = {https://openreview.net/forum?id=SkeHuCVFDr}
}

@misc{ffci,
  doi       = {10.48550/ARXIV.2011.13662},
  url       = {https://arxiv.org/abs/2011.13662},
  author    = {Koto, Fajri and Baldwin, Timothy and Lau, Jey Han},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {FFCI: A Framework for Interpretable Automatic Evaluation of Summarization},
  publisher = {arXiv},
  year      = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{yasunaga-etal-2021-lm,
  title     = {{LM}-Critic: Language Models for Unsupervised Grammatical Error Correction},
  author    = {Yasunaga, Michihiro  and
               Leskovec, Jure  and
               Liang, Percy},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.emnlp-main.611},
  doi       = {10.18653/v1/2021.emnlp-main.611},
  pages     = {7752--7763}
}

@inproceedings{wang-etal-2020-asking,
  title     = {Asking and Answering Questions to Evaluate the Factual Consistency of Summaries},
  author    = {Wang, Alex  and
               Cho, Kyunghyun  and
               Lewis, Mike},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-main.450},
  doi       = {10.18653/v1/2020.acl-main.450},
  pages     = {5008--5020}
}

@inproceedings{aly2021feverous,
  title     = {{FEVEROUS}: Fact Extraction and {VER}ification Over Unstructured and Structured information},
  author    = {Rami Aly and Zhijiang Guo and Michael Sejr Schlichtkrull and James Thorne and Andreas Vlachos and Christos Christodoulopoulos and Oana Cocarascu and Arpit Mittal},
  booktitle = {Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},
  year      = {2021},
  url       = {https://openreview.net/forum?id=h-flVCIlstW}
}

@inproceedings{arkhipov2019tuning,
  title     = {Tuning Multilingual Transformers for Language-Specific Named Entity Recognition},
  author    = {Arkhipov, Mikhail  and
               Trofimova, Maria  and
               Kuratov, Yuri  and
               Sorokin, Alexey},
  booktitle = {Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing},
  month     = aug,
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W19-3712},
  doi       = {10.18653/v1/W19-3712},
  pages     = {89--93},
  abstract  = {Our paper addresses the problem of multilingual named entity recognition on the material of 4 languages: Russian, Bulgarian, Czech and Polish. We solve this task using the BERT model. We use a hundred languages multilingual model as base for transfer to the mentioned Slavic languages. Unsupervised pre-training of the BERT model on these 4 languages allows to significantly outperform baseline neural approaches and multilingual BERT. Additional improvement is achieved by extending BERT with a word-level CRF layer. Our system was submitted to BSNLP 2019 Shared Task on Multilingual Named Entity Recognition and demonstrated top performance in multilingual setting for two competition metrics. We open-sourced NER models and BERT model pre-trained on the four Slavic languages.}
}

@inproceedings{augenstein2019multifc,
  title     = {{M}ulti{FC}: A Real-World Multi-Domain Dataset for Evidence-Based Fact Checking of Claims},
  author    = {Augenstein, Isabelle  and
               Lioma, Christina  and
               Wang, Dongsheng  and
               Chaves Lima, Lucas  and
               Hansen, Casper  and
               Hansen, Christian  and
               Simonsen, Jakob Grue},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  month     = nov,
  year      = {2019},
  address   = {Hong Kong, China},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D19-1475},
  doi       = {10.18653/v1/D19-1475},
  pages     = {4685--4697},
  abstract  = {We contribute the largest publicly available dataset of naturally occurring factual claims for the purpose of automatic claim verification. It is collected from 26 fact checking websites in English, paired with textual sources and rich metadata, and labelled for veracity by human expert journalists. We present an in-depth analysis of the dataset, highlighting characteristics and challenges. Further, we present results for automatic veracity prediction, both with established baselines and with a novel method for joint ranking of evidence pages and predicting veracity that outperforms all baselines. Significant performance increases are achieved by encoding evidence, and by modelling metadata. Our best-performing model achieves a Macro F1 of 49.2{\%}, showing that this is a challenging testbed for claim veracity prediction.}
}

@article{beltagy2020longformer,
  title   = {Longformer: The Long-Document Transformer},
  author  = {Iz Beltagy and Matthew E. Peters and Arman Cohan},
  journal = {arXiv:2004.05150},
  year    = {2020}
}

@article{bender2018data,
  title   = {Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science},
  author  = {Bender, Emily M.  and Friedman, Batya},
  journal = {Transactions of the Association for Computational Linguistics},
  volume  = {6},
  year    = {2018},
  url     = {https://aclanthology.org/Q18-1041},
  doi     = {10.1162/tacl_a_00041},
  pages   = {587--604}
}

@article{binau2020danish,
  title  = {Danish Fact Verification: An End-to-End Machine Learning System for Automatic Fact-Checking of Danish Textual Claims},
  author = {Binau, Julie and Schulte, Henri},
  year   = {2020}
}

@inproceedings{bowman2015large,
  title     = {A large annotated corpus for learning natural language inference},
  author    = {Bowman, Samuel R.  and
               Angeli, Gabor  and
               Potts, Christopher  and
               Manning, Christopher D.},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  month     = sep,
  year      = {2015},
  address   = {Lisbon, Portugal},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D15-1075},
  doi       = {10.18653/v1/D15-1075},
  pages     = {632--642}
}

@inproceedings{brod6ley1996identifying,
  author    = {Brodley, Carla E. and Friedl, Mark A.},
  title     = {Identifying and Eliminating Mislabeled Training Instances},
  year      = {1996},
  isbn      = {026251091X},
  publisher = {AAAI Press},
  abstract  = {This paper presents a new approach to identifying and eliminating mislabeled training instances. The goal of this technique is to improve classification accuracies produced by learning algorithms by improving the quality of the training data. The approach employs an ensemble of classifiers that serve as a filter for the training data. Using an n-fold cross validation, the training data is passed through the filter. Only instances that the filter classifies correctly are passed to the final learning algorithm. We present an empirical evaluation of the approach for the task of automated land cover mapping from remotely sensed data. Labeling error arises in these data from a multitude of sources including lack of consistency in the vegetation classification used, variable measurement techniques, and variation in the spatial sampling resolution. Our evaluation shows that for noise levels of less than 40%, filtering results in higher predictive accuracy than not filtering, and for levels of class noise less than or equal to 20% filtering allows the base-line accuracy to be retained. Our empirical results suggest that the ensemble filter approach is an effective method for identifying labeling errors, and further, that the approach will significantly benefit ongoing research to develop accurate and robust remote sensing-based methods to map land cover at global scales.},
  booktitle = {Proceedings of the Thirteenth National Conference on Artificial Intelligence - Volume 1},
  pages     = {799–805},
  numpages  = {7},
  location  = {Portland, Oregon},
  series    = {AAAI'96}
}

@inproceedings{burtsev2018deeppavlov,
  title     = {{D}eep{P}avlov: Open-Source Library for Dialogue Systems},
  author    = {Burtsev, Mikhail  and
               Seliverstov, Alexander  and
               Airapetyan, Rafael  and
               Arkhipov, Mikhail  and
               Baymurzina, Dilyara  and
               Bushkov, Nickolay  and
               Gureenkova, Olga  and
               Khakhulin, Taras  and
               Kuratov, Yuri  and
               Kuznetsov, Denis  and
               Litinsky, Alexey  and
               Logacheva, Varvara  and
               Lymar, Alexey  and
               Malykh, Valentin  and
               Petrov, Maxim  and
               Polulyakh, Vadim  and
               Pugachev, Leonid  and
               Sorokin, Alexey  and
               Vikhreva, Maria  and
               Zaynutdinov, Marat},
  booktitle = {Proceedings of {ACL} 2018, System Demonstrations},
  month     = jul,
  year      = {2018},
  address   = {Melbourne, Australia},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P18-4021},
  doi       = {10.18653/v1/P18-4021},
  pages     = {122--127},
  abstract  = {Adoption of messaging communication and voice assistants has grown rapidly in the last years. This creates a demand for tools that speed up prototyping of feature-rich dialogue systems. An open-source library DeepPavlov is tailored for development of conversational agents. The library prioritises efficiency, modularity, and extensibility with the goal to make it easier to develop dialogue systems from scratch and with limited data available. It supports modular as well as end-to-end approaches to implementation of conversational agents. Conversational agent consists of skills and every skill can be decomposed into components. Components are usually models which solve typical NLP tasks such as intent classification, named entity recognition or pre-trained word vectors. Sequence-to-sequence chit-chat skill, question answering skill or task-oriented skill can be assembled from components provided in the library.}
}

@inproceedings{chang2020twotower,
  title     = {Pre-training Tasks for Embedding-based Large-scale Retrieval},
  author    = {Wei-Cheng Chang and Felix X. Yu and Yin-Wen Chang and Yiming Yang and Sanjiv Kumar},
  booktitle = {International Conference on Learning Representations},
  year      = {2020},
  url       = {https://openreview.net/forum?id=rkg-mA4FDr}
}

@inproceedings{chatzikyriakidis2017overview,
  title     = {An overview of Natural Language Inference Data Collection: The way forward?},
  author    = {Chatzikyriakidis, Stergios  and
               Cooper, Robin  and
               Dobnik, Simon  and
               Larsson, Staffan},
  booktitle = {Proceedings of the Computing Natural Language Inference Workshop},
  year      = {2017},
  url       = {https://aclanthology.org/W17-7203}
}

@misc{deepl,
  author       = {\textsf{DeepL}},
  year         = {2021},
  title        = {DeepL Translator},
  howpublished = {\url{https://www.deepl.com/en/translator}},
  note         = {Accessed: 2021-05-09}
}

@inproceedings{derczynski2020maintaining,
  title     = {Maintaining Quality in {FEVER} Annotation},
  author    = {Derczynski, Leon  and
               Binau, Julie  and
               Schulte, Henri},
  booktitle = {Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.fever-1.6},
  doi       = {10.18653/v1/2020.fever-1.6},
  pages     = {42--46},
  abstract  = {We propose two measures for measuring the quality of constructed claims in the FEVER task. Annotating data for this task involves the creation of supporting and refuting claims over a set of evidence. Automatic annotation processes often leave superficial patterns in data, which learning systems can detect instead of performing the underlying task. Humans also can leave these superficial patterns, either voluntarily or involuntarily (due to e.g. fatigue). The two measures introduced attempt to detect the impact of these superficial patterns. One is a new information-theoretic and distributionality based measure, \textit{DCI}; and the other an extension of neural probing work over the ARCT task, \textit{utility}. We demonstrate these measures over a recent major dataset, that from the English FEVER task in 2019.}
}

@inproceedings{ferreira2016emergent,
  title     = {{E}mergent: a novel data-set for stance classification},
  author    = {Ferreira, William  and
               Vlachos, Andreas},
  booktitle = {Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = jun,
  year      = {2016},
  address   = {San Diego, California},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/N16-1138},
  doi       = {10.18653/v1/N16-1138},
  pages     = {1163--1168}
}

@article{fleiss1971measuring,
  author    = {Fleiss, Joseph L.},
  title     = {Measuring nominal scale agreement among many raters.},
  journal   = {Psychological Bulletin},
  year      = {1971},
  publisher = {American Psychological Association},
  address   = {US},
  volume    = {76},
  number    = {5},
  pages     = {378-382},
  keywords  = {*Measurement; *Psychiatric Patients; *Psychodiagnosis; Statistical Analysis},
  abstract  = {Introduced the statistic kappa to measure nominal scale agreement between a fixed pair of raters. Kappa was generalized to the case where each of a sample of 30 patients was rated on a nominal scale by the same number of psychiatrist raters (n = 6), but where the raters rating 1 s were not necessarily the same as those rating another. Large sample standard errors were derived. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  doi       = {10.1037/h0031619},
  url       = {https://doi.org/10.1037/h0031619}
}

@article{frenay2013classification,
  title     = {Classification in the presence of label noise: a survey},
  author    = {Fr{\'e}nay, Beno{\^\i}t and Verleysen, Michel},
  journal   = {IEEE transactions on neural networks and learning systems},
  volume    = {25},
  number    = {5},
  pages     = {845--869},
  year      = {2013},
  publisher = {IEEE}
}

@misc{googletranslation,
  author       = {\textsf{Google}},
  year         = {2021},
  title        = {Cloud Translation - Google Cloud},
  howpublished = {\url{https://cloud.google.com/translate}},
  note         = {Accessed: 2021-05-09}
}

@inproceedings{gupta2021xfact,
  title     = {{X}-Fact: A New Benchmark Dataset for Multilingual Fact Checking},
  author    = {Gupta, Ashim  and
               Srikumar, Vivek},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-short.86},
  doi       = {10.18653/v1/2021.acl-short.86},
  pages     = {675--682},
  abstract  = {In this work, we introduce : the largest publicly available multilingual dataset for factual verification of naturally existing real-world claims. The dataset contains short statements in 25 languages and is labeled for veracity by expert fact-checkers. The dataset includes a multilingual evaluation benchmark that measures both out-of-domain generalization, and zero-shot capabilities of the multilingual models. Using state-of-the-art multilingual transformer-based models, we develop several automated fact-checking models that, along with textual claims, make use of additional metadata and evidence from news stories retrieved using a search engine. Empirically, our best model attains an F-score of around 40{\%}, suggesting that our dataset is a challenging benchmark for the evaluation of multilingual fact-checking models.}
}

@article{hassan2017claimbuster,
  author     = {Hassan, Naeemul and Zhang, Gensheng and Arslan, Fatma and Caraballo, Josue and Jimenez, Damian and Gawsane, Siddhant and Hasan, Shohedul and Joseph, Minumol and Kulkarni, Aaditya and Nayak, Anil Kumar and Sable, Vikas and Li, Chengkai and Tremayne, Mark},
  title      = {ClaimBuster: The First-Ever End-to-End Fact-Checking System},
  year       = {2017},
  issue_date = {August 2017},
  publisher  = {VLDB Endowment},
  volume     = {10},
  number     = {12},
  issn       = {2150-8097},
  url        = {https://doi.org/10.14778/3137765.3137815},
  doi        = {10.14778/3137765.3137815},
  abstract   = {Our society is struggling with an unprecedented amount of falsehoods, hyperboles, and half-truths. Politicians and organizations repeatedly make the same false claims. Fake news floods the cyberspace and even allegedly influenced the 2016 election. In fighting false information, the number of active fact-checking organizations has grown from 44 in 2014 to 114 in early 2017. 1 Fact-checkers vet claims by investigating relevant data and documents and publish their verdicts. For instance, PolitiFact.com, one of the earliest and most popular fact-checking projects, gives factual claims truthfulness ratings such as True, Mostly True, Half true, Mostly False, False, and even "Pants on Fire". In the U.S., the election year made fact-checking a part of household terminology. For example, during the first presidential debate on September 26, 2016, NPR.org's live fact-checking website drew 7.4 million page views and delivered its biggest traffic day ever.},
  journal    = {Proc. VLDB Endow.},
  month      = {aug},
  pages      = {1945–1948},
  numpages   = {4}
}

@inproceedings{kazemi2021claim,
  title     = {Claim Matching Beyond {E}nglish to Scale Global Fact-Checking},
  author    = {Kazemi, Ashkan  and
               Garimella, Kiran  and
               Gaffney, Devin  and
               Hale, Scott},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-long.347},
  doi       = {10.18653/v1/2021.acl-long.347},
  pages     = {4504--4517},
  abstract  = {Manual fact-checking does not scale well to serve the needs of the internet. This issue is further compounded in non-English contexts. In this paper, we discuss claim matching as a possible solution to scale fact-checking. We define claim matching as the task of identifying pairs of textual messages containing claims that can be served with one fact-check. We construct a novel dataset of WhatsApp tipline and public group messages alongside fact-checked claims that are first annotated for containing “claim-like statements” and then matched with potentially similar items and annotated for claim matching. Our dataset contains content in high-resource (English, Hindi) and lower-resource (Bengali, Malayalam, Tamil) languages. We train our own embedding model using knowledge distillation and a high-quality “teacher” model in order to address the imbalance in embedding quality between the low- and high-resource languages in our dataset. We provide evaluations on the performance of our solution and compare with baselines and existing state-of-the-art multilingual embedding models, namely LASER and LaBSE. We demonstrate that our performance exceeds LASER and LaBSE in all settings. We release our annotated datasets, codebooks, and trained embedding model to allow for further research.}
}

@inproceedings{khattab2020colbert,
  author    = {Khattab, Omar and Zaharia, Matei},
  title     = {{ColBERT}: Efficient and Effective Passage Search via Contextualized Late Interaction over {BERT}},
  year      = {2020},
  isbn      = {9781450380164},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/3397271.3401075},
  abstract  = {Recent progress in Natural Language Understanding (NLU) is driving fast-paced advances
               in Information Retrieval (IR), largely owed to fine-tuning deep language models (LMs)
               for document ranking. While remarkably effective, the ranking models based on these
               LMs increase computational cost by orders of magnitude over prior approaches, particularly
               as they must feed each query-document pair through a massive neural network to compute
               a single relevance score. To tackle this, we present ColBERT, a novel ranking model
               that adapts deep LMs (in particular, BERT) for efficient retrieval. ColBERT introduces
               a late interaction architecture that independently encodes the query and the document
               using BERT and then employs a cheap yet powerful interaction step that models their
               fine-grained similarity. By delaying and yet retaining this fine-granular interaction,
               ColBERT can leverage the expressiveness of deep LMs while simultaneously gaining the
               ability to pre-compute document representations offline, considerably speeding up
               query processing. Crucially, ColBERT's pruning-friendly interaction mechanism enables
               leveraging vector-similarity indexes for end-to-end retrieval directly from millions
               of documents. We extensively evaluate ColBERT using two recent passage search datasets.
               Results show that ColBERT's effectiveness is competitive with existing BERT-based
               models (and outperforms every non-BERT baseline), while executing two orders-of-magnitude
               faster and requiring up to four orders-of-magnitude fewer FLOPs per query.},
  booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages     = {39–48},
  numpages  = {10},
  keywords  = {deep language models, bert, efficiency, neural ir},
  location  = {Virtual Event, China},
  series    = {SIGIR '20}
}

@article{kiss2006punkt,
  title   = {Unsupervised Multilingual Sentence Boundary Detection},
  author  = {Kiss, Tibor  and
             Strunk, Jan},
  journal = {Computational Linguistics},
  volume  = {32},
  number  = {4},
  year    = {2006},
  url     = {https://aclanthology.org/J06-4003},
  doi     = {10.1162/coli.2006.32.4.485},
  pages   = {485--525}
}

@inproceedings{kitaev2020reformer,
  title     = {Reformer: The Efficient Transformer},
  author    = {Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},
  booktitle = {International Conference on Learning Representations},
  year      = {2020},
  url       = {https://openreview.net/forum?id=rkgNKkHtvB}
}

@article{hayes2007krippendorff,
  author  = {Hayes, Andrew and Krippendorff, Klaus},
  year    = {2007},
  month   = {04},
  pages   = {77-89},
  title   = {Answering the Call for a Standard Reliability Measure for Coding Data},
  volume  = {1},
  journal = {Communication Methods and Measures},
  doi     = {10.1080/19312450709336664}
}

@inproceedings{lan2020albert,
  title     = {{ALBERT}: A Lite {BERT} for Self-supervised Learning of Language Representations},
  author    = {Zhenzhong Lan and Mingda Chen and Sebastian Goodman and Kevin Gimpel and Piyush Sharma and Radu Soricut},
  booktitle = {International Conference on Learning Representations},
  year      = {2020},
  url       = {https://openreview.net/forum?id=H1eA7AEtvS}
}

@article{landis1977measurement,
  issn      = {0006341X, 15410420},
  url       = {http://www.jstor.org/stable/2529310},
  abstract  = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.},
  author    = {J. Richard Landis and Gary G. Koch},
  journal   = {Biometrics},
  number    = {1},
  pages     = {159--174},
  publisher = {[Wiley, International Biometric Society]},
  title     = {The Measurement of Observer Agreement for Categorical Data},
  volume    = {33},
  year      = {1977}
}

@inproceedings{lee2019latent,
  title     = {Latent Retrieval for Weakly Supervised Open Domain Question Answering},
  author    = {Lee, Kenton  and
               Chang, Ming-Wei  and
               Toutanova, Kristina},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P19-1612},
  doi       = {10.18653/v1/P19-1612},
  pages     = {6086--6096},
  abstract  = {Recent work on open domain question answering (QA) assumes strong supervision of the supporting evidence and/or assumes a blackbox information retrieval (IR) system to retrieve evidence candidates. We argue that both are suboptimal, since gold evidence is not always available, and QA is fundamentally different from IR. We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system. In this setting, evidence retrieval from all of Wikipedia is treated as a latent variable. Since this is impractical to learn from scratch, we pre-train the retriever with an Inverse Cloze Task. We evaluate on open versions of five QA datasets. On datasets where the questioner already knows the answer, a traditional IR system such as BM25 is sufficient. On datasets where a user is genuinely seeking an answer, we show that learned retrieval is crucial, outperforming BM25 by up to 19 points in exact match.}
}

@inproceedings{lin2021pyserini,
  author    = {Lin, Jimmy and Ma, Xueguang and Lin, Sheng-Chieh and Yang, Jheng-Hong and Pradeep, Ronak and Nogueira, Rodrigo},
  title     = {Pyserini: A {Python} Toolkit for Reproducible Information Retrieval Research with Sparse and Dense Representations},
  year      = {2021},
  isbn      = {9781450380379},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/3404835.3463238},
  abstract  = {Pyserini is a Python toolkit for reproducible information retrieval research with
               sparse and dense representations. It aims to provide effective, reproducible, and
               easy-to-use first-stage retrieval in a multi-stage ranking architecture. Our toolkit
               is self-contained as a standard Python package and comes with queries, relevance judgments,
               pre-built indexes, and evaluation scripts for many commonly used IR test collections.
               We aim to support, out of the box, the entire research lifecycle of efforts aimed
               at improving ranking with modern neural approaches. In particular, Pyserini supports
               sparse retrieval (e.g., BM25 scoring using bag-of-words representations), dense retrieval
               (e.g., nearest-neighbor search on transformer-encoded representations), as well as
               hybrid retrieval that integrates both approaches. This paper provides an overview
               of toolkit features and presents empirical results that illustrate its effectiveness
               on two popular ranking tasks. Around this toolkit, our group has built a culture of
               reproducibility through shared norms and tools that enable rigorous automated testing.},
  booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages     = {2356–2362},
  numpages  = {7},
  keywords  = {open-source search engine, first-stage retrieval},
  location  = {Virtual Event, Canada},
  series    = {SIGIR '21}
}

@article{murayama2021dataset,
  title   = {Dataset of Fake News Detection and Fact Verification: A Survey},
  author  = {Murayama, Taichi},
  journal = {arXiv preprint arXiv:2111.03299},
  year    = {2021}
}

@inproceedings{nakov2021automated,
  title     = {Automated Fact-Checking for Assisting Human Fact-Checkers},
  author    = {Nakov, Preslav and Corney, David and Hasanain, Maram and Alam, Firoj and Elsayed, Tamer and Barrón-Cedeño, Alberto and Papotti, Paolo and Shaar, Shaden and Da San Martino, Giovanni},
  booktitle = {Proceedings of the Thirtieth International Joint Conference on
               Artificial Intelligence, {IJCAI-21}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Zhi-Hua Zhou},
  pages     = {4551--4558},
  year      = {2021},
  month     = {8},
  note      = {Survey Track},
  doi       = {10.24963/ijcai.2021/619},
  url       = {https://doi.org/10.24963/ijcai.2021/619}
}

@inproceedings{niven2019probing,
  title     = {Probing Neural Network Comprehension of Natural Language Arguments},
  author    = {Niven, Timothy  and
               Kao, Hung-Yu},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P19-1459},
  doi       = {10.18653/v1/P19-1459},
  pages     = {4658--4664},
  abstract  = {We are surprised to find that BERT’s peak performance of 77{\%} on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.}
}

@inproceedings{norregaard2021danfever,
  title     = {{D}an{FEVER}: claim verification dataset for {D}anish},
  author    = {N{\o}rregaard, Jeppe  and
               Derczynski, Leon},
  booktitle = {Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa)},
  month     = {May31--2June},
  year      = {2021},
  address   = {Reykjavik, Iceland (Online)},
  publisher = {Link{\"o}ping University Electronic Press, Sweden},
  url       = {https://aclanthology.org/2021.nodalida-main.47},
  pages     = {422--428},
  abstract  = {We present a dataset, DanFEVER, intended for multilingual misinformation research. The dataset is in Danish and has the same format as the well-known English FEVER dataset. It can be used for testing methods in multilingual settings, as well as for creating models in production for the Danish language.}
}

@inproceedings{papineni2002bleu,
  author    = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  title     = {{BLEU}: A Method for Automatic Evaluation of Machine Translation},
  year      = {2002},
  publisher = {Association for Computational Linguistics},
  address   = {USA},
  url       = {https://doi.org/10.3115/1073083.1073135},
  doi       = {10.3115/1073083.1073135},
  abstract  = {Human evaluations of machine translation are extensive but expensive. Human evaluations
               can take months to finish and involve human labor that can not be reused. We propose
               a method of automatic machine translation evaluation that is quick, inexpensive, and
               language-independent, that correlates highly with human evaluation, and that has little
               marginal cost per run. We present this method as an automated understudy to skilled
               human judges which substitutes for them when there is need for quick or frequent evaluations.},
  booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
  pages     = {311–318},
  numpages  = {8},
  location  = {Philadelphia, Pennsylvania},
  series    = {ACL '02}
}

@inproceedings{parikh2016decomposable,
  title     = {A Decomposable Attention Model for Natural Language Inference},
  author    = {Parikh, Ankur  and
               T{\"a}ckstr{\"o}m, Oscar  and
               Das, Dipanjan  and
               Uszkoreit, Jakob},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2016},
  address   = {Austin, Texas},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D16-1244},
  doi       = {10.18653/v1/D16-1244},
  pages     = {2249--2255}
}

@inproceedings{pires201multilingual,
  title     = {How Multilingual is Multilingual {BERT}?},
  author    = {Pires, Telmo  and
               Schlinger, Eva  and
               Garrette, Dan},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P19-1493},
  doi       = {10.18653/v1/P19-1493},
  pages     = {4996--5001},
  abstract  = {In this paper, we show that Multilingual BERT (M-BERT), released by Devlin et al. (2018) as a single language model pre-trained from monolingual corpora in 104 languages, is surprisingly good at zero-shot cross-lingual model transfer, in which task-specific annotations in one language are used to fine-tune the model for evaluation in another language. To understand why, we present a large number of probing experiments, showing that transfer is possible even to languages in different scripts, that transfer works best between typologically similar languages, that monolingual corpora can train models for code-switching, and that the model can find translation pairs. From these results, we can conclude that M-BERT does create multilingual representations, but that these representations exhibit systematic deficiencies affecting certain language pairs.}
}

@article{popel2020Transforming,
  journal = {Nature Communications},
  title   = {Transforming machine translation: a deep learning system reaches news translation quality comparable to human professionals},
  author  = {Martin Popel and Marketa Tomkova and Jakub Tomek and {\L}ukasz Kaiser and Jakob Uszkoreit and Ond{\v{r}}ej Bojar and Zden{\v{e}}k {\v{Z}}abokrtsk{\'{y}}},
  year    = {2020},
  volume  = {11},
  number  = {4381},
  pages   = {1--15},
  issn    = {2041-1723},
  doi     = {10.1038/s41467-020-18073-9},
  url     = {https://www.nature.com/articles/s41467-020-18073-9}
}

@inproceedings{post2018sacrebleu,
  title     = {A Call for Clarity in Reporting {BLEU} Scores},
  author    = {Post, Matt},
  booktitle = {Proceedings of the Third Conference on Machine Translation: Research Papers},
  month     = oct,
  year      = {2018},
  address   = {Brussels, Belgium},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W18-6319},
  doi       = {10.18653/v1/W18-6319},
  pages     = {186--191},
  abstract  = {The field of machine translation faces an under-recognized problem because of inconsistency in the reporting of scores from its dominant metric. Although people refer to “the” BLEU score, BLEU is in fact a parameterized metric whose values can vary wildly with changes to these parameters. These parameters are often not reported or are hard to find, and consequently, BLEU scores between papers cannot be directly compared. I quantify this variation, finding differences as high as 1.8 between commonly used configurations. The main culprit is different tokenization and normalization schemes applied to the reference. Pointing to the success of the parsing community, I suggest machine translation researchers settle upon the BLEU scheme used by the annual Conference on Machine Translation (WMT), which does not allow for user-supplied reference processing, and provide a new tool, SACREBLEU, to facilitate this.}
}

@inproceedings{rajpurkar2016squad,
  title     = {{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text},
  author    = {Rajpurkar, Pranav  and
               Zhang, Jian  and
               Lopyrev, Konstantin  and
               Liang, Percy},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2016},
  address   = {Austin, Texas},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D16-1264},
  doi       = {10.18653/v1/D16-1264},
  pages     = {2383--2392}
}

@inproceedings{sathe2020automated,
  title     = {Automated Fact-Checking of Claims from {W}ikipedia},
  author    = {Sathe, Aalok  and
               Ather, Salar  and
               Le, Tuan Manh  and
               Perry, Nathan  and
               Park, Joonsuk},
  booktitle = {Proceedings of the 12th Language Resources and Evaluation Conference},
  month     = may,
  year      = {2020},
  address   = {Marseille, France},
  publisher = {European Language Resources Association},
  url       = {https://aclanthology.org/2020.lrec-1.849},
  pages     = {6874--6882},
  abstract  = {Automated fact checking is becoming increasingly vital as both truthful and fallacious information accumulate online. Research on fact checking has benefited from large-scale datasets such as FEVER and SNLI. However, such datasets suffer from limited applicability due to the synthetic nature of claims and/or evidence written by annotators that differ from real claims and evidence on the internet. To this end, we present WikiFactCheck-English, a dataset of 124k+ triples consisting of a claim, context and an evidence document extracted from English Wikipedia articles and citations, as well as 34k+ manually written claims that are refuted by the evidence documents. This is the largest fact checking dataset consisting of real claims and evidence to date; it will allow the development of fact checking systems that can better process claims and evidence in the real world. We also show that for the NLI subtask, a logistic regression system trained using existing and novel features achieves peak accuracy of 68{\%}, providing a competitive baseline for future work. Also, a decomposable attention model trained on SNLI significantly underperforms the models trained on this dataset, suggesting that models trained on manually generated data may not be sufficiently generalizable or suitable for fact checking real-world claims.},
  language  = {English},
  isbn      = {979-10-95546-34-4}
}

@inproceedings{shahi2020fakecovid,
  title     = {Fake{C}ovid -- A Multilingual Cross-domain Fact Check News Dataset for COVID-19},
  author    = {Shahi, Gautam Kishore and Nandini, Durgesh},
  booktitle = {Workshop Proceedings of the 14th International {AAAI} {C}onference on {W}eb and {S}ocial {M}edia},
  year      = {2020},
  url       = {http://workshop-proceedings.icwsm.org/pdf/2020_14.pdf}
}

@misc{sido2021czert,
  title         = {Czert -- Czech {BERT}-like Model for Language Representation},
  author        = {Jakub Sido and Ondřej Pražák and Pavel Přibáň and Jan Pašek and Michal Seják and Miloslav Konopík},
  year          = {2021},
  eprint        = {2103.13031},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{straka2021robeczech,
  title     = {{RobeCzech}: Czech {RoBERTa}, a Monolingual Contextualized Language Representation Model},
  isbn      = {9783030835279},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-030-83527-9_17},
  doi       = {10.1007/978-3-030-83527-9_17},
  journal   = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  author    = {Straka, Milan and Náplava, Jakub and Straková, Jana and Samuel, David},
  year      = {2021},
  pages     = {197–209}
}

@inproceedings{thorne2018automated,
  title     = {Automated Fact Checking: Task Formulations, Methods and Future Directions},
  author    = {Thorne, James  and
               Vlachos, Andreas},
  booktitle = {Proceedings of the 27th International Conference on Computational Linguistics},
  month     = aug,
  year      = {2018},
  address   = {Santa Fe, New Mexico, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/C18-1283},
  pages     = {3346--3359},
  abstract  = {The recently increased focus on misinformation has stimulated research in fact checking, the task of assessing the truthfulness of a claim. Research in automating this task has been conducted in a variety of disciplines including natural language processing, machine learning, knowledge representation, databases, and journalism. While there has been substantial progress, relevant papers and articles have been published in research communities that are often unaware of each other and use inconsistent terminology, thus impeding understanding and further progress. In this paper we survey automated fact checking research stemming from natural language processing and related disciplines, unifying the task formulations and methodologies across papers and authors. Furthermore, we highlight the use of evidence as an important distinguishing factor among them cutting across task formulations and methods. We conclude with proposing avenues for future NLP research on automated fact checking.}
}

@inproceedings{wang2017liar,
  title     = {“{L}iar, Liar Pants on Fire”: A New Benchmark Dataset for Fake News Detection},
  author    = {Wang, William Yang},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  month     = jul,
  year      = {2017},
  address   = {Vancouver, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P17-2067},
  doi       = {10.18653/v1/P17-2067},
  pages     = {422--426},
  abstract  = {Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts. However, statistical approaches to combating fake news has been dramatically limited by the lack of labeled benchmark datasets. In this paper, we present LIAR: a new, publicly available dataset for fake news detection. We collected a decade-long, 12.8K manually labeled short statements in various contexts from PolitiFact.com, which provides detailed analysis report and links to source documents for each case. This dataset can be used for fact-checking research as well. Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type. Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns. We have designed a novel, hybrid convolutional neural network to integrate meta-data with text. We show that this hybrid approach can improve a text-only deep learning model.}
}

@article{Fiser2015poornet,
  author   = {Fi{\v{s}}er, Darja
              and Sagot, Beno{\^i}t},
  title    = {Constructing a poor man's wordnet in a resource-rich world},
  journal  = {Language Resources and Evaluation},
  year     = {2015},
  month    = {Sep},
  day      = {01},
  volume   = {49},
  number   = {3},
  pages    = {601-635},
  abstract = {In this paper we present a language-independent, fully modular and automatic approach to bootstrap a wordnet for a new language by recycling different types of already existing language resources, such as machine-readable dictionaries, parallel corpora, and Wikipedia. The approach, which we apply here to Slovene, takes into account monosemous and polysemous words, general and specialised vocabulary as well as simple and multi-word lexemes. The extracted words are then assigned one or several synset ids, based on a classifier that relies on several features including distributional similarity. Finally, we identify and remove highly dubious (literal, synset) pairs, based on simple distributional information extracted from a large corpus in an unsupervised way. Automatic, manual and task-based evaluations show that the resulting resource, the latest version of the Slovene wordnet, is already a valuable source of lexico-semantic information.},
  issn     = {1574-0218},
  doi      = {10.1007/s10579-015-9295-6},
  url      = {https://doi.org/10.1007/s10579-015-9295-6}
}

@article{xiong2021nystromformer,
  title     = {Nystr{\"o}mformer: A Nystr{\"o}m-based Algorithm for Approximating Self-Attention},
  author    = {Xiong, Yunyang and Zeng, Zhanpeng and Chakraborty, Rudrasis and Tan, Mingxing and Fung, Glenn and Li, Yin and Singh, Vikas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year      = {2021}
}

@article{zeng2021fcsurvey,
  author   = {Zeng, Xia and Abumansour, Amani S. and Zubiaga, Arkaitz},
  title    = {Automated fact-checking: A survey},
  journal  = {Language and Linguistics Compass},
  volume   = {15},
  number   = {10},
  pages    = {e12438},
  doi      = {https://doi.org/10.1111/lnc3.12438},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/lnc3.12438},
  abstract = {Abstract As online false information continues to grow, automated fact-checking has gained an increasing amount of attention in recent years. Researchers in the field of Natural Language Processing (NLP) have contributed to the task by building fact-checking datasets, devising automated fact-checking pipelines and proposing NLP methods to further research in the development of different components. This article reviews relevant research on automated fact-checking covering both the claim detection and claim validation components.},
  year     = {2021}
}

@inproceedings{yang2019hype,
  author    = {Yang, Wei and Lu, Kuang and Yang, Peilin and Lin, Jimmy},
  title     = {Critically Examining the "Neural Hype": Weak Baselines and the Additivity of Effectiveness Gains from Neural Ranking Models},
  year      = {2019},
  isbn      = {9781450361729},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/3331184.3331340},
  abstract  = {Is neural IR mostly hype? In a recent SIGIR Forum article, Lin expressed skepticism
               that neural ranking models were actually improving ad hoc retrieval effectiveness
               in limited data scenarios. He provided anecdotal evidence that authors of neural IR
               papers demonstrate "wins" by comparing against weak baselines. This paper provides
               a rigorous evaluation of those claims in two ways: First, we conducted a meta-analysis
               of papers that have reported experimental results on the TREC Robust04 test collection.
               We do not find evidence of an upward trend in effectiveness over time. In fact, the
               best reported results are from a decade ago and no recent neural approach comes close.
               Second, we applied five recent neural models to rerank the strong baselines that Lin
               used to make his arguments. A significant improvement was observed for one of the
               models, demonstrating additivity in gains. While there appears to be merit to neural
               IR approaches, at least some of the gains reported in the literature appear illusory.},
  booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages     = {1129–1132},
  numpages  = {4},
  keywords  = {document ranking, meta-analysis, neural IR},
  location  = {Paris, France},
  series    = {SIGIR'19}
}

@article{dabre2020mtsurvey,
  author     = {Dabre, Raj and Chu, Chenhui and Kunchukuttan, Anoop},
  title      = {A Survey of Multilingual Neural Machine Translation},
  year       = {2020},
  issue_date = {September 2021},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {53},
  number     = {5},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3406095},
  doi        = {10.1145/3406095},
  abstract   = {We present a survey on multilingual neural machine translation (MNMT), which has gained a lot of traction in recent years. MNMT has been useful in improving translation quality as a result of translation knowledge transfer (transfer learning). MNMT is more promising and interesting than its statistical machine translation counterpart, because end-to-end modeling and distributed representations open new avenues for research on machine translation. Many approaches have been proposed to exploit multilingual parallel corpora for improving translation quality. However, the lack of a comprehensive survey makes it difficult to determine which approaches are promising and, hence, deserve further exploration. In this article, we present an in-depth survey of existing literature on MNMT. We first categorize various approaches based on their central use-case and then further categorize them based on resource scenarios, underlying modeling principles, core-issues, and challenges. Wherever possible, we address the strengths and weaknesses of several techniques by comparing them with each other. We also discuss the future directions for MNMT. This article is aimed towards both beginners and experts in NMT. We hope this article will serve as a starting point as well as a source of new ideas for researchers and engineers interested in MNMT.},
  journal    = {ACM Comput. Surv.},
  month      = {sep},
  articleno  = {99},
  numpages   = {38},
  keywords   = {Neural machine translation, multi-source, zero-shot, multilingualism, low-resource, survey}
}

@article{vstromajerova2016between,
  title   = {Between comparable and parallel: English-czech corpus from wikipedia},
  author  = {{\v{S}}tromajerov{\'a}, Ad{\'e}la and Baisa, V{\'\i}t and Blahu{\v{s}}, Marek},
  journal = {RASLAN 2016 Recent Advances in Slavonic Natural Language Processing},
  pages   = {3},
  year    = {2016}
}

@article{Althobaiti2021Wikiparallel,
  author  = {Althobaiti, Maha Jarallah},
  journal = {IEEE Access},
  title   = {A Simple Yet Robust Algorithm for Automatic Extraction of Parallel Sentences: A Case Study on Arabic-English Wikipedia Articles},
  year    = {2022},
  volume  = {10},
  number  = {},
  pages   = {401-420},
  doi     = {10.1109/ACCESS.2021.3137830}
}

@inproceedings{chu-etal-2014-constructing,
  title     = {Constructing a {C}hinese{---}{J}apanese Parallel Corpus from {W}ikipedia},
  author    = {Chu, Chenhui  and
               Nakazawa, Toshiaki  and
               Kurohashi, Sadao},
  booktitle = {Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)},
  month     = may,
  year      = {2014},
  address   = {Reykjavik, Iceland},
  publisher = {European Language Resources Association (ELRA)},
  url       = {http://www.lrec-conf.org/proceedings/lrec2014/pdf/21_Paper.pdf},
  pages     = {642--647},
  abstract  = {Parallel corpora are crucial for statistical machine translation (SMT). However, they are quite scarce for most language pairs, such as Chinese―Japanese. As comparable corpora are far more available, many studies have been conducted to automatically construct parallel corpora from comparable corpora. This paper presents a robust parallel sentence extraction system for constructing a Chinese―Japanese parallel corpus from Wikipedia. The system is inspired by previous studies that mainly consist of a parallel sentence candidate filter and a binary classifier for parallel sentence identification. We improve the system by using the common Chinese characters for filtering and two novel feature sets for classification. Experiments show that our system performs significantly better than the previous studies for both accuracy in parallel sentence extraction and SMT performance. Using the system, we construct a Chinese―Japanese parallel corpus with more than 126k highly accurate parallel sentences from Wikipedia. The constructed parallel corpus is freely available at http://orchid.kuee.kyoto-u.ac.jp/{\textasciitilde}chu/resource/wiki{\_}zh{\_}ja.tgz.}
}

@inproceedings{mohammadi2010parallelwiki,
  author    = {Mohammadi, Mehdi and GhasemAghaee, Nasser},
  booktitle = {2010 Second International Conference on Computer Engineering and Applications},
  title     = {Building Bilingual Parallel Corpora Based on Wikipedia},
  year      = {2010},
  volume    = {2},
  number    = {},
  pages     = {264-268},
  doi       = {10.1109/ICCEA.2010.203}
}

@article{krippendorff1970,
  author  = {Klaus Krippendorff},
  title   = {Estimating the Reliability, Systematic Error and Random Error of Interval Data},
  journal = {Educational and Psychological Measurement},
  volume  = {30},
  number  = {1},
  pages   = {61-70},
  year    = {1970},
  doi     = {10.1177/001316447003000105},
  url     = {         https://doi.org/10.1177/001316447003000105
             
             }
}

@inproceedings{guyon1994patterns,
  author    = {Guyon, I. and Mati\'{c}, N. and Vapnik, V.},
  title     = {Discovering Informative Patterns and Data Cleaning},
  year      = {1994},
  publisher = {AAAI Press},
  address   = {Palo Alto, California, USA},
  abstract  = {We present a method for discovering informative patterns from data. With this method, large databases can be reduced to only a few representative data entries. Our framework encompasses also methods for cleaning databases containing corrupted data. Both on-line and off-line algorithms are proposed and experimentally checked on databases of handwritten images. The generality of the framework makes it an attractive candidate for new applications in knowledge discovery.},
  booktitle = {Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining},
  pages     = {145–156},
  numpages  = {12},
  keywords  = {machine learning, information gain, knowledge discovery, data cleaning, informative patterns},
  location  = {Seattle, WA},
  series    = {AAAIWS'94}
}

@inproceedings{10.1007/978-3-642-02319-4_50,
  author    = {Miranda, Andr{\'e} L. B.
               and Garcia, Lu{\'i}s Paulo F.
               and Carvalho, Andr{\'e} C. P. L. F.
               and Lorena, Ana C.},
  editor    = {Corchado, Emilio
               and Wu, Xindong
               and Oja, Erkki
               and Herrero, {\'A}lvaro
               and Baruque, Bruno},
  title     = {Use of Classification Algorithms in Noise Detection and Elimination},
  booktitle = {Hybrid Artificial Intelligence Systems},
  year      = {2009},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {417--424},
  abstract  = {Data sets in Bioinformatics usually present a high level of noise. Various processes involved in biological data collection and preparation may be responsible for the introduction of this noise, such as the imprecision inherent to laboratory experiments generating these data. Using noisy data in the induction of classifiers through Machine Learning techniques may harm the classifiers prediction performance. Therefore, the predictions of these classifiers may be used for guiding noise detection and removal. This work compares three approaches for the elimination of noisy data from Bioinformatics data sets using Machine Learning classifiers: the first is based in the removal of the detected noisy examples, the second tries to reclassify these data and the third technique, named hybrid, unifies the previous approaches.},
  isbn      = {978-3-642-02319-4}
}

@article{Jeatrakul,
  author  = {Jeatrakul, Piyasak and Wong, Kok and Fung, Chun},
  year    = {2010},
  month   = {04},
  pages   = {297-302},
  title   = {Data Cleaning for Classification Using Misclassification Analysis},
  volume  = {14},
  journal = {JACIII},
  doi     = {10.20965/jaciii.2010.p0297}
}

@inproceedings{priban-etal-2019-machine,
  title     = {Machine Learning Approach to Fact-Checking in {W}est {S}lavic Languages},
  author    = {P{\v{r}}ib{\'a}{\v{n}}, Pavel  and
               Hercig, Tom{\'a}{\v{s}}  and
               Steinberger, Josef},
  booktitle = {Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)},
  month     = sep,
  year      = {2019},
  address   = {Varna, Bulgaria},
  publisher = {INCOMA Ltd.},
  url       = {https://aclanthology.org/R19-1113},
  doi       = {10.26615/978-954-452-056-4_113},
  pages     = {973--979},
  abstract  = {Fake news detection and closely-related fact-checking have recently attracted a lot of attention. Automatization of these tasks has been already studied for English. For other languages, only a few studies can be found (e.g. (Baly et al., 2018)), and to the best of our knowledge, no research has been conducted for West Slavic languages. In this paper, we present datasets for Czech, Polish, and Slovak. We also ran initial experiments which set a baseline for further research into this area.}
}

@inproceedings{strakova14,
  author    = {Strakov\'{a}, Jana  and  Straka, Milan  and  Haji\v{c}, Jan},
  title     = {Open-{S}ource {T}ools for {M}orphology, {L}emmatization, {POS} {T}agging and {N}amed {E}ntity {R}ecognition},
  booktitle = {Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
  month     = {June},
  year      = {2014},
  address   = {Baltimore, Maryland},
  publisher = {Association for Computational Linguistics},
  pages     = {13--18},
  url       = {http://www.aclweb.org/anthology/P/P14/P14-5003.pdf}
}

@article{lora,
  author     = {Edward J. Hu and
                Yelong Shen and
                Phillip Wallis and
                Zeyuan Allen{-}Zhu and
                Yuanzhi Li and
                Shean Wang and
                Weizhu Chen},
  title      = {LoRA: Low-Rank Adaptation of Large Language Models},
  journal    = {CoRR},
  volume     = {abs/2106.09685},
  year       = {2021},
  url        = {\url{https://arxiv.org/abs/2106.09685}},
  eprinttype = {arXiv},
  eprint     = {2106.09685},
  timestamp  = {Tue, 29 Jun 2021 16:55:04 +0200}
}

@misc{bing,
  title         = {Complex Claim Verification with Evidence Retrieved in the Wild},
  author        = {Jifan Chen and Grace Kim and Aniruddh Sriram and Greg Durrett and Eunsol Choi},
  year          = {2023},
  eprint        = {2305.11859},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{llama2,
  title         = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  author        = {Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  year          = {2023},
  eprint        = {2307.09288},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{llama,
  title         = {LLaMA: Open and Efficient Foundation Language Models},
  author        = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
  year          = {2023},
  eprint        = {2302.13971},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{llms,
  title         = {A Survey of Large Language Models},
  author        = {Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
  year          = {2023},
  eprint        = {2303.18223},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{prompting,
  author     = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  title      = {Pre-Train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
  year       = {2023},
  issue_date = {September 2023},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {55},
  number     = {9},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3560815},
  doi        = {10.1145/3560815},
  abstract   = {This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g.,&nbsp;the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website including constantly updated survey and paperlist.},
  journal    = {ACM Comput. Surv.},
  month      = {jan},
  articleno  = {195},
  numpages   = {35},
  keywords   = {Pre-trained language models, prompting}
}

@article{Ji_2023,
  doi       = {10.1145/3571730},
  url       = {https://doi.org/10.1145%2F3571730},
  year      = 2023,
  month     = {mar},
  publisher = {Association for Computing Machinery ({ACM})},
  volume    = {55},
  number    = {12},
  pages     = {1--38},
  author    = {Ziwei Ji and Nayeon Lee and Rita Frieske and Tiezheng Yu and Dan Su and Yan Xu and Etsuko Ishii and Ye Jin Bang and Andrea Madotto and Pascale Fung},
  title     = {Survey of Hallucination in Natural Language Generation},
  journal   = {{ACM} Computing Surveys}
}

@article{georgiana_stanescu_2022_6795674,
  author  = {Georgiana Stănescu},
  title   = {{Ukraine conflict: the challenge of informational 
             war}},
  journal = {SOCIAL SCIENCES AND EDUCATION RESEARCH REVIEW},
  year    = 2022,
  volume  = 9,
  number  = 1,
  pages   = {146-148},
  month   = jul,
  doi     = {10.5281/zenodo.6795674},
  url     = {https://doi.org/10.5281/zenodo.6795674}
}

@unknown{glorin,
  author = {Sebastian, Glorin},
  year   = {2023},
  month  = {05},
  pages  = {},
  title  = {Exploring Ethical Implications of ChatGPT and Other AI Chatbots and Regulation of Disinformation Propagation}
}

@misc{peft,
  title         = {Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning},
  author        = {Haokun Liu and Derek Tam and Mohammed Muqeeth and Jay Mohta and Tenghao Huang and Mohit Bansal and Colin Raffel},
  year          = {2022},
  eprint        = {2205.05638},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{openassistant,
  title         = {OpenAssistant Conversations -- Democratizing Large Language Model Alignment},
  author        = {Andreas Köpf and Yannic Kilcher and Dimitri von Rütte and Sotiris Anagnostidis and Zhi-Rui Tam and Keith Stevens and Abdullah Barhoum and Nguyen Minh Duc and Oliver Stanley and Richárd Nagyfi and Shahul ES and Sameer Suri and David Glushkov and Arnav Dantuluri and Andrew Maguire and Christoph Schuhmann and Huu Nguyen and Alexander Mattick},
  year          = {2023},
  eprint        = {2304.07327},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{choi-etal-2021-decontextualization,
  title     = {Decontextualization: Making Sentences Stand-Alone},
  author    = {Choi, Eunsol  and
               Palomaki, Jennimaria  and
               Lamm, Matthew  and
               Kwiatkowski, Tom  and
               Das, Dipanjan  and
               Collins, Michael},
  journal   = {Transactions of the Association for Computational Linguistics},
  volume    = {9},
  year      = {2021},
  address   = {Cambridge, MA},
  publisher = {MIT Press},
  url       = {https://aclanthology.org/2021.tacl-1.27},
  doi       = {10.1162/tacl_a_00377},
  pages     = {447--461},
  abstract  = {Models for question answering, dialogue agents, and summarization often interpret the meaning of a sentence in a rich context and use that meaning in a new context. Taking excerpts of text can be problematic, as key pieces may not be explicit in a local window. We isolate and define the problem of sentence decontextualization: taking a sentence together with its context and rewriting it to be interpretable out of context, while preserving its meaning. We describe an annotation procedure, collect data on the Wikipedia corpus, and use the data to train models to automatically decontextualize sentences. We present preliminary studies that show the value of sentence decontextualization in a user-facing task, and as preprocessing for systems that perform document understanding. We argue that decontextualization is an important subtask in many downstream applications, and that the definitions and resources provided can benefit tasks that operate on sentences that occur in a richer context.}
}

@misc{mohri2023learning,
  title         = {Learning to Reject with a Fixed Predictor: Application to Decontextualization},
  author        = {Christopher Mohri and Daniel Andor and Eunsol Choi and Michael Collins},
  year          = {2023},
  eprint        = {2301.09044},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@inproceedings{lin-2004-rouge,
  title     = {{ROUGE}: A Package for Automatic Evaluation of Summaries},
  author    = {Lin, Chin-Yew},
  booktitle = {Text Summarization Branches Out},
  month     = jul,
  year      = {2004},
  address   = {Barcelona, Spain},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W04-1013},
  pages     = {74--81}
}

@inproceedings{fernet,
  author    = {Lehe{\v{c}}ka, Jan
               and {\v{S}}vec, Jan},
  editor    = {Espinosa-Anke, Luis
               and Mart{\'i}n-Vide, Carlos
               and Spasi{\'{c}}, Irena},
  title     = {Comparison of Czech Transformers on Text Classification Tasks},
  booktitle = {Statistical Language and Speech Processing},
  year      = {2021},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {27--37},
  abstract  = {In this paper, we present our progress in pre-training monolingual Transformers for Czech and contribute to the research community by releasing our models for public. The need for such models emerged from our effort to employ Transformers in our language-specific tasks, but we found the performance of the published multilingual models to be very limited. Since the multilingual models are usually pre-trained from 100+ languages, most of low-resourced languages (including Czech) are under-represented in these models. At the same time, there is a huge amount of monolingual training data available in web archives like Common Crawl. We have pre-trained and publicly released two monolingual Czech Transformers and compared them with relevant public models, trained (at least partially) for Czech. The paper presents the Transformers pre-training procedure as well as a comparison of pre-trained models on text classification task from various domains.},
  isbn      = {978-3-030-89579-2}
}

@misc{mikolov,
  title         = {Efficient Estimation of Word Representations in Vector Space},
  author        = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  year          = {2013},
  eprint        = {1301.3781},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{pennington-etal-2014-glove,
  title     = {{G}lo{V}e: Global Vectors for Word Representation},
  author    = {Pennington, Jeffrey  and
               Socher, Richard  and
               Manning, Christopher},
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
  month     = oct,
  year      = {2014},
  address   = {Doha, Qatar},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D14-1162},
  doi       = {10.3115/v1/D14-1162},
  pages     = {1532--1543}
}

@misc{kocian2021siamese,
  title         = {Siamese BERT-based Model for Web Search Relevance Ranking Evaluated on a New Czech Dataset},
  author        = {Matěj Kocián and Jakub Náplava and Daniel Štancl and Vladimír Kadlec},
  year          = {2021},
  eprint        = {2112.01810},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR}
}

@inproceedings{mroczkowski-etal-2021-herbert,
  title     = {{H}er{BERT}: Efficiently Pretrained Transformer-based Language Model for {P}olish},
  author    = {Mroczkowski, Robert  and
               Rybak, Piotr  and
               Wr{\'o}blewska, Alina  and
               Gawlik, Ireneusz},
  booktitle = {Proceedings of the 8th Workshop on Balto-Slavic Natural Language Processing},
  month     = apr,
  year      = {2021},
  address   = {Kiyv, Ukraine},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.bsnlp-1.1},
  pages     = {1--10},
  abstract  = {BERT-based models are currently used for solving nearly all Natural Language Processing (NLP) tasks and most often achieve state-of-the-art results. Therefore, the NLP community conducts extensive research on understanding these models, but above all on designing effective and efficient training procedures. Several ablation studies investigating how to train BERT-like models have been carried out, but the vast majority of them concerned only the English language. A training procedure designed for English does not have to be universal and applicable to other especially typologically different languages. Therefore, this paper presents the first ablation study focused on Polish, which, unlike the isolating English language, is a fusional language. We design and thoroughly evaluate a pretraining procedure of transferring knowledge from multilingual to monolingual BERT-based models. In addition to multilingual model initialization, other factors that possibly influence pretraining are also explored, i.e. training objective, corpus size, BPE-Dropout, and pretraining length. Based on the proposed procedure, a Polish BERT-based language model {--} HerBERT {--} is trained. This model achieves state-of-the-art results on multiple downstream tasks.}
}

@misc{pikuliak2021slovakbert,
  title         = {SlovakBERT: Slovak Masked Language Model},
  author        = {Matúš Pikuliak and Štefan Grivalský and Martin Konôpka and Miroslav Blšták and Martin Tamajka and Viktor Bachratý and Marián Šimko and Pavol Balážik and Michal Trnka and Filip Uhlárik},
  year          = {2021},
  eprint        = {2109.15254},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{Liu_2023,
  doi       = {10.1016/j.metrad.2023.100017},
  url       = {https://doi.org/10.1016%2Fj.metrad.2023.100017},
  year      = 2023,
  month     = {sep},
  publisher = {Elsevier {BV}},
  volume    = {1},
  number    = {2},
  pages     = {100017},
  author    = {Yiheng Liu and Tianle Han and Siyuan Ma and Jiayue Zhang and Yuanyuan Yang and Jiaming Tian and Hao He and Antong Li and Mengshen He and Zhengliang Liu and Zihao Wu and Lin Zhao and Dajiang Zhu and Xiang Li and Ning Qiang and Dingang Shen and Tianming Liu and Bao Ge},
  title     = {Summary of {ChatGPT}-Related research and perspective towards the future of large language models},
  journal   = {Meta-Radiology}
}

@misc{dettmers2023qlora,
      title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{disorder,
author = {Wardle, Claire and Derakhshan, Hossein},
year = {2017},
month = {09},
pages = {},
title = {INFORMATION DISORDER : Toward an interdisciplinary framework for research and policy making Information Disorder Toward an interdisciplinary framework for research and policymaking}
}

@inproceedings{fnc,
    title = "A Retrospective Analysis of the Fake News Challenge Stance-Detection Task",
    author = "Hanselowski, Andreas  and
      PVS, Avinesh  and
      Schiller, Benjamin  and
      Caspelherr, Felix  and
      Chaudhuri, Debanjan  and
      Meyer, Christian M.  and
      Gurevych, Iryna",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/C18-1158",
    pages = "1859--1874",
    abstract = "The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance classification task as a crucial first step towards detecting fake news. To date, there is no in-depth analysis paper to critically discuss FNC-1’s experimental setup, reproduce the results, and draw conclusions for next-generation stance classification methods. In this paper, we provide such an in-depth analysis for the three top-performing systems. We first find that FNC-1’s proposed evaluation metric favors the majority class, which can be easily classified, and thus overestimates the true discriminative power of the methods. Therefore, we propose a new F1-based metric yielding a changed system ranking. Next, we compare the features and architectures used, which leads to a novel feature-rich stacked LSTM model that performs on par with the best systems, but is superior in predicting minority classes. To understand the methods’ ability to generalize, we derive a new dataset and perform both in-domain and cross-domain experiments. Our qualitative and quantitative study helps interpreting the original FNC-1 scores and understand which features help improving performance and why. Our new dataset and all source code used during the reproduction study are publicly available for future research.",
}

@article{DBLP:journals/corr/abs-2103-08541,
  author       = {Tal Schuster and
                  Adam Fisch and
                  Regina Barzilay},
  title        = {Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence},
  journal      = {CoRR},
  volume       = {abs/2103.08541},
  year         = {2021},
  url          = {https://arxiv.org/abs/2103.08541},
  eprinttype    = {arXiv},
  eprint       = {2103.08541},
  timestamp    = {Tue, 23 Mar 2021 16:29:47 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2103-08541.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{clef21,
      title={Overview of the CLEF--2021 CheckThat! Lab on Detecting Check-Worthy Claims, Previously Fact-Checked Claims, and Fake News}, 
      author={Preslav Nakov and Giovanni Da San Martino and Tamer Elsayed and Alberto Barrón-Cedeño and Rubén Míguez and Shaden Shaar and Firoj Alam and Fatima Haouari and Maram Hasanain and Watheq Mansour and Bayan Hamdan and Zien Sheikh Ali and Nikolay Babulkov and Alex Nikolov and Gautam Kishore Shahi and Julia Maria Struß and Thomas Mandl and Mucahid Kutlu and Yavuz Selim Kartal},
      year={2021},
      eprint={2109.12987},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{clef19,
      title={Overview of the CLEF-2019 CheckThat!: Automatic Identification and Verification of Claims}, 
      author={Tamer Elsayed and Preslav Nakov and Alberto Barrón-Cedeño and Maram Hasanain and Reem Suwaileh and Giovanni Da San Martino and Pepa Atanasova},
      year={2021},
      eprint={2109.15118},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{narayan-etal-2018-dont,
    title = "Don’t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization",
    author = "Narayan, Shashi  and
      Cohen, Shay B.  and
      Lapata, Mirella",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month     = {October-November},
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1206",
    doi = "10.18653/v1/D18-1206",
    pages = "1797--1807",
    abstract = "We introduce “extreme summarization”, a new single-document summarization task which does not favor extractive strategies and calls for an abstractive modeling approach. The idea is to create a short, one-sentence news summary answering the question “What is the article about?”. We collect a real-world, large-scale dataset for this task by harvesting online articles from the British Broadcasting Corporation (BBC). We propose a novel abstractive model which is conditioned on the article’s topics and based entirely on convolutional neural networks. We demonstrate experimentally that this architecture captures long-range dependencies in a document and recognizes pertinent content, outperforming an oracle extractive system and state-of-the-art abstractive approaches when evaluated automatically and by humans.",
}

@inproceedings{banerjee-lavie-2005-meteor,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
    author = "Banerjee, Satanjeev  and
      Lavie, Alon",
    booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W05-0909",
    pages = "65--72",
}

@inproceedings{stefanik,
    title = "Resources and Few-shot Learners for In-context Learning in {S}lavic Languages",
    author = "{\v{S}}tef{\'a}nik, Michal  and
      Kadl{\v{c}}{\'\i}k, Marek  and
      Gramacki, Piotr  and
      Sojka, Petr",
    booktitle = "Proceedings of the 9th Workshop on Slavic Natural Language Processing 2023 (SlavicNLP 2023)",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.bsnlp-1.12",
    pages = "94--105",
    abstract = "Despite the rapid recent progress in creating accurate and compact in-context learners, most recent work focuses on in-context learning (ICL) for tasks in English. However, the ability to interact with users of languages outside English presents a great potential for broadening the applicability of language technologies to non-English speakers.In this work, we collect the infrastructure necessary for training and evaluation of ICL in a selection of Slavic languages: Czech, Polish, and Russian. We link a diverse set of datasets and cast these into a unified instructional format through a set of transformations and newly-crafted templates written purely in target languages.Using the newly-curated dataset, we evaluate a set of the most recent in-context learners and compare their results to the supervised baselines. Finally, we train, evaluate and publish a set of in-context learning models that we train on the collected resources and compare their performance to previous work.We find that ICL models tuned in English are also able to learn some tasks from non-English contexts, but multilingual instruction fine-tuning consistently improves the ICL ability. We also find that the massive multitask training can be outperformed by single-task training in the target language, uncovering the potential for specializing in-context learners to the language(s) of their application.",
}

@inproceedings{suppa-adamec-2020-summarization,
    title = "A Summarization Dataset of {S}lovak News Articles",
    author = "Šuppa, Marek  and
      Adamec, Jerguš",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.830",
    pages = "6725--6730",
    abstract = "As a well established NLP task, single-document summarization has seen significant interest in the past few years. However, most of the work has been done on English datasets. This is particularly noticeable in the context of evaluation where the dominant ROUGE metric assumes its input to be written in English. In this paper we aim to address both of these issues by introducing a summarization dataset of articles from a popular Slovak news site and proposing small adaptation to the ROUGE metric that make it better suited for Slovak texts. Several baselines are evaluated on the dataset, including an extractive approach based on the Multilingual version of the BERT architecture. To the best of our knowledge, the presented dataset is the first large-scale news-based summarization dataset for text written in Slovak language. It can be reproduced using the utilities available at https://github.com/NaiveNeuron/sme-sum",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@misc{conneau2018xnli,
      title={XNLI: Evaluating Cross-lingual Sentence Representations}, 
      author={Alexis Conneau and Guillaume Lample and Ruty Rinott and Adina Williams and Samuel R. Bowman and Holger Schwenk and Veselin Stoyanov},
      year={2018},
      eprint={1809.05053},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{mbart,
      title={Multilingual Denoising Pre-training for Neural Machine Translation}, 
      author={Yinhan Liu and Jiatao Gu and Naman Goyal and Xian Li and Sergey Edunov and Marjan Ghazvininejad and Mike Lewis and Luke Zettlemoyer},
      year={2020},
      eprint={2001.08210},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{brio,
    title = "{BRIO}: Bringing Order to Abstractive Summarization",
    author = "Liu, Yixin  and
      Liu, Pengfei  and
      Radev, Dragomir  and
      Neubig, Graham",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.207",
    doi = "10.18653/v1/2022.acl-long.207",
    pages = "2890--2903",
    abstract = "Abstractive summarization models are commonly trained using maximum likelihood estimation, which assumes a deterministic (one-point) target distribution in which an ideal model will assign all the probability mass to the reference summary. This assumption may lead to performance degradation during inference, where the model needs to compare several system-generated (candidate) summaries that have deviated from the reference summary. To address this problem, we propose a novel training paradigm which assumes a non-deterministic distribution so that different candidate summaries are assigned probability mass according to their quality. Our method achieves a new state-of-the-art result on the CNN/DailyMail (47.78 ROUGE-1) and XSum (49.07 ROUGE-1) datasets. Further analysis also shows that our model can estimate probabilities of candidate summaries that are more correlated with their level of quality.",
}

@misc{pegasus,
      title={PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization}, 
      author={Jingqing Zhang and Yao Zhao and Mohammad Saleh and Peter J. Liu},
      year={2020},
      eprint={1912.08777},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{topp,
      title={The Curious Case of Neural Text Degeneration}, 
      author={Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
      year={2020},
      eprint={1904.09751},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{straka-etal-2018-sumeczech,
    title = "{S}ume{C}zech: Large {C}zech News-Based Summarization Dataset",
    author = "Straka, Milan  and
      Mediankin, Nikita  and
      Kocmi, Tom  and
      {\v{Z}}abokrtsk{\'y}, Zden{\v{e}}k  and
      Hude{\v{c}}ek, Vojt{\v{e}}ch  and
      Haji{\v{c}}, Jan",
    booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
    month = may,
    year = "2018",
    address = "Miyazaki, Japan",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L18-1551",
}

@inproceedings{szwoch-etal-2022-creation,
    title = "Creation of {P}olish Online News Corpus for Political Polarization Studies",
    author = "Szwoch, Joanna  and
      Staszkow, Mateusz  and
      Rzepka, Rafal  and
      Araki, Kenji",
    booktitle = "Proceedings of the LREC 2022 workshop on Natural Language Processing for Political Sciences",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.politicalnlp-1.12",
    pages = "86--90",
    abstract = "In this paper we describe a Polish news corpus as an attempt to create a filtered, organized and representative set of texts coming from contemporary online press articles from two major Polish TV news providers: commercial TVN24 and state-owned TVP Info. The process consists of web scraping, data cleaning and formatting. A random sample was selected from prepared data to perform a classification task. The random forest achieved the best prediction results out of all considered models. We believe that this dataset is a valuable contribution to existing Polish language corpora as online news are considered to be formal and relatively mistake-free, therefore, a reliable source of correct written language, unlike other online platforms such as blogs or social media. Furthermore, to our knowledge, such corpus from this period of time has not been created before. In the future we would like to expand this dataset with articles coming from other online news providers, repeat the classification task on a bigger scale, utilizing other algorithms. Our data analysis outcomes might be a relevant basis to improve research on a political polarization and propaganda techniques in media.",
}

@article{SAEED2023110273,
title = {Explainable AI (XAI): A systematic meta-survey of current challenges and future opportunities},
journal = {Knowledge-Based Systems},
volume = {263},
pages = {110273},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110273},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123000230},
author = {Waddah Saeed and Christian Omlin},
keywords = {Explainable AI (XAI), Interpretable AI, Black-box, Machine learning, Deep learning, Meta-survey, Responsible AI},
abstract = {The past decade has seen significant progress in artificial intelligence (AI), which has resulted in algorithms being adopted for resolving a variety of problems. However, this success has been met by increasing model complexity and employing black-box AI models that lack transparency. In response to this need, Explainable AI (XAI) has been proposed to make AI more transparent and thus advance the adoption of AI in critical domains. Although there are several reviews of XAI topics in the literature that have identified challenges and potential research directions of XAI, these challenges and research directions are scattered. This study, hence, presents a systematic meta-survey of challenges and future research directions in XAI organized in two themes: (1) general challenges and research directions of XAI and (2) challenges and research directions of XAI based on machine learning life cycle’s phases: design, development, and deployment. We believe that our meta-survey contributes to XAI literature by providing a guide for future exploration in the XAI area.}
}

@inproceedings{rag,
  address =       {Red Hook, NY, USA},
  author =        {Lewis, Patrick and Perez, Ethan and
                   Piktus, Aleksandra and Petroni, Fabio and
                   Karpukhin, Vladimir and Goyal, Naman and
                   K\"{u}ttler, Heinrich and Lewis, Mike and
                   Yih, Wen-tau and Rockt\"{a}schel, Tim and
                   Riedel, Sebastian and Kiela, Douwe},
  booktitle =     {Proceedings of the 34th International Conference on
                   Neural Information Processing Systems},
  publisher =     {Curran Associates Inc.},
  series =        {NIPS '20},
  title =         {Retrieval-augmented generation for
                   knowledge-intensive NLP tasks},
  year =          {2020},
  abstract =      {Large pre-trained language models have been shown to
                   store factual knowledge in their parameters, and
                   achieve state-of-the-art results when fine-tuned on
                   downstream NLP tasks. However, their ability to
                   access and precisely manipulate knowledge is still
                   limited, and hence on knowledge-intensive tasks,
                   their performance lags behind task-specific
                   architectures. Additionally, providing provenance for
                   their decisions and updating their world knowledge
                   remain open research problems. Pre-trained models
                   with a differentiable access mechanism to explicit
                   non-parametric memory can overcome this issue, but
                   have so far been only investigated for extractive
                   downstream tasks. We explore a general-purpose
                   fine-tuning recipe for retrieval-augmented generation
                   (RAG) — models which combine pre-trained parametric
                   and non-parametric memory for language generation. We
                   introduce RAG models where the parametric memory is a
                   pre-trained seq2seq model and the non-parametric
                   memory is a dense vector index of Wikipedia, accessed
                   with a pre-trained neural retriever. We compare two
                   RAG formulations, one which conditions on the same
                   retrieved passages across the whole generated
                   sequence, and another which can use different
                   passages per token. We fine-tune and evaluate our
                   models on a wide range of knowledge-intensive NLP
                   tasks and set the state of the art on three open
                   domain QA tasks, outperforming parametric seq2seq
                   models and task-specific retrieve-and-extract
                   architectures. For language generation tasks, we find
                   that RAG models generate more specific, diverse and
                   factual language than a state-of-the-art
                   parametric-only seq2seq baseline.},
  isbn =          {9781713829546},
  url =           {https://proceedings.neurips.cc/paper_files/paper/2020/file/
                  6b493230205f780e1bc26945df7481e5-Paper.pdf},
}

@inproceedings{averitec2024,
  address =       {Red Hook, NY, USA},
  author =        {Schlichtkrull, Michael and Guo, Zhijiang and
                   Vlachos, Andreas},
  booktitle =     {Proceedings of the 37th International Conference on
                   Neural Information Processing Systems},
  publisher =     {Curran Associates Inc.},
  series =        {NIPS '23},
  title =         {AVERITEC: a dataset for real-world claim verification
                   with evidence from the web},
  year =          {2024},
  abstract =      {Existing datasets for automated fact-checking have
                   substantial limitations, such as relying on
                   artificial claims, lacking annotations for evidence
                   and intermediate reasoning, or including evidence
                   published after the claim. In this paper, we
                   introduce AVERITEC, a new dataset of 4,568 real-world
                   claims covering fact-checks by 50 different
                   organizations. Each claim is annotated with
                   question-answer pairs supported by evidence available
                   online, as well as textual justifications explaining
                   how the evidence combines to produce a verdict.
                   Through a multi-round annotation process, we avoid
                   common pitfalls including context dependence,
                   evidence insufficiency, and temporal leakage, and
                   reach a substantial inter-annotator agreement of κ =
                   0.619 on verdicts. We develop a baseline as well as
                   an evaluation scheme for verifying claims through
                   question-answering against the open web.},
  url =           {https://dl.acm.org/doi/10.5555/3666122.3668964},
}

@inproceedings{thorne-etal-2018-fact,
  address =       {Brussels, Belgium},
  author =        {Thorne, James and Vlachos, Andreas and
                   Cocarascu, Oana and Christodoulopoulos, Christos and
                   Mittal, Arpit},
  booktitle =     {Proceedings of the First Workshop on Fact Extraction
                   and {VER}ification ({FEVER})},
  editor =        {Thorne, James and Vlachos, Andreas and
                   Cocarascu, Oana and Christodoulopoulos, Christos and
                   Mittal, Arpit},
  month =         nov,
  pages =         {1--9},
  publisher =     {Association for Computational Linguistics},
  title =         {The Fact Extraction and {VER}ification ({FEVER})
                   Shared Task},
  year =          {2018},
  doi =           {10.18653/v1/W18-5501},
  url =           {https://aclanthology.org/W18-5501},
}

@inproceedings{thorne-etal-2018-fever,
  address =       {New Orleans, Louisiana},
  author =        {Thorne, James and Vlachos, Andreas and
                   Christodoulopoulos, Christos and Mittal, Arpit},
  booktitle =     {Proceedings of the 2018 Conference of the North
                   {A}merican Chapter of the Association for
                   Computational Linguistics: Human Language
                   Technologies, Volume 1 (Long Papers)},
  editor =        {Walker, Marilyn and Ji, Heng and Stent, Amanda},
  month =         jun,
  pages =         {809--819},
  publisher =     {Association for Computational Linguistics},
  title =         {{FEVER}: a Large-scale Dataset for Fact Extraction
                   and {VER}ification},
  year =          {2018},
  doi =           {10.18653/v1/N18-1074},
  url =           {https://aclanthology.org/N18-1074},
}

@article{Ullrich2023,
  author =        {Ullrich, Herbert and Drchal, Jan and
                   R{\'y}par, Martin and Vincourov{\'a}, Hana and
                   Moravec, V{\'a}clav},
  journal =       {Language Resources and Evaluation},
  month =         {Dec},
  number =        {4},
  pages =         {1571-1605},
  title =         {CsFEVER and CTKFacts: acquiring Czech data for fact
                   verification},
  volume =        {57},
  year =          {2023},
  abstract =      {In this paper, we examine several methods of
                   acquiring Czech data for automated fact-checking,
                   which is a task commonly modeled as a classification
                   of textual claim veracity w.r.t. a corpus of trusted
                   ground truths. We attempt to collect sets of data in
                   form of a factual claim, evidence within the ground
                   truth corpus, and its veracity label (supported,
                   refuted or not enough info). As a first attempt, we
                   generate a Czech version of the large-scale FEVER
                   dataset built on top of Wikipedia corpus. We take a
                   hybrid approach of machine translation and document
                   alignment; the approach and the tools we provide can
                   be easily applied to other languages. We discuss its
                   weaknesses, propose a future strategy for their
                   mitigation and publish the 127k resulting
                   translations, as well as a version of such dataset
                   reliably applicable for the Natural Language
                   Inference task---the CsFEVER-NLI. Furthermore, we
                   collect a novel dataset of 3,097 claims, which is
                   annotated using the corpus of 2.2 M articles of
                   Czech News Agency. We present an extended dataset
                   annotation methodology based on the FEVER approach,
                   and, as the underlying corpus is proprietary, we also
                   publish a standalone version of the dataset for the
                   task of Natural Language Inference we call
                   CTKFactsNLI. We analyze both acquired datasets for
                   spurious cues---annotation patterns leading to model
                   overfitting. CTKFacts is further examined for
                   inter-annotator agreement, thoroughly cleaned, and a
                   typology of common annotator errors is extracted.
                   Finally, we provide baseline models for all stages of
                   the fact-checking pipeline and publish the NLI
                   datasets, as well as our annotation platform and
                   other experimental data.},
  doi =           {10.1007/s10579-023-09654-3},
  issn =          {1574-0218},
  url =           {https://doi.org/10.1007/s10579-023-09654-3},
}

@misc{dejean2024thoroughcomparisoncrossencodersllms,
  author =        {Hervé Déjean and Stéphane Clinchant and
                   Thibault Formal},
  title =         {A Thorough Comparison of Cross-Encoders and LLMs for
                   Reranking SPLADE},
  year =          {2024},
  url =           {https://arxiv.org/abs/2403.10407},
}

@inproceedings{muennighoff-etal-2023-mteb,
  address =       {Dubrovnik, Croatia},
  author =        {Muennighoff, Niklas and Tazi, Nouamane and
                   Magne, Loic and Reimers, Nils},
  booktitle =     {Proceedings of the 17th Conference of the European
                   Chapter of the Association for Computational
                   Linguistics},
  editor =        {Vlachos, Andreas and Augenstein, Isabelle},
  month =         may,
  pages =         {2014--2037},
  publisher =     {Association for Computational Linguistics},
  title =         {{MTEB}: Massive Text Embedding Benchmark},
  year =          {2023},
  doi =           {10.18653/v1/2023.eacl-main.148},
  url =           {https://aclanthology.org/2023.eacl-main.148},
}

@inproceedings{li-li-2024-aoe,
  address =       {Bangkok, Thailand},
  author =        {Li, Xianming and Li, Jing},
  booktitle =     {Proceedings of the 62nd Annual Meeting of the
                   Association for Computational Linguistics (Volume 1:
                   Long Papers)},
  editor =        {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
  month =         aug,
  pages =         {1825--1839},
  publisher =     {Association for Computational Linguistics},
  title =         {{A}o{E}: Angle-optimized Embeddings for Semantic
                   Textual Similarity},
  year =          {2024},
  abstract =      {Text embedding is pivotal in semantic textual
                   similarity (STS) tasks, which are crucial components
                   in Large Language Model (LLM) applications. STS
                   learning largely relies on the cosine function as the
                   optimization objective to reflect semantic
                   similarity. However, the cosine has saturation zones
                   rendering vanishing gradients and hindering learning
                   subtle semantic differences in text embeddings. To
                   address this issue, we propose a novel
                   Angle-optimized Embedding model, AoE. It optimizes
                   angle differences in complex space to explore
                   similarity in saturation zones better. To set up a
                   comprehensive evaluation, we experimented with
                   existing short-text STS, our newly collected
                   long-text STS, and downstream task datasets.
                   Extensive experimental results on STS and MTEB
                   benchmarks show that AoE significantly outperforms
                   popular text embedding models neglecting cosine
                   saturation zones. It highlights that AoE can produce
                   high-quality text embeddings and broadly benefit
                   downstream tasks.},
  url =           {https://aclanthology.org/2024.acl-long.101},
}

@misc{emb2024mxbai,
  author =        {Sean Lee and Aamir Shakir and Darius Koenig and
                   Julius Lipp},
  title =         {Open Source Strikes Bread - New Fluffy Embeddings
                   Model},
  year =          {2024},
  url =           {https://www.mixedbread.ai/blog/mxbai-embed-large-v1},
}

@article{douze2024faiss,
  author =        {Matthijs Douze and Alexandr Guzhva and Chengqi Deng and
                   Jeff Johnson and Gergely Szilvasy and
                   Pierre-Emmanuel Mazaré and Maria Lomeli and
                   Lucas Hosseini and Hervé Jégou},
  title =         {The Faiss library},
  year =          {2024},
}

@article{johnson2019billion,
  author =        {Johnson, Jeff and Douze, Matthijs and
                   J{\'e}gou, Herv{\'e}},
  journal =       {IEEE Transactions on Big Data},
  number =        {3},
  pages =         {535--547},
  publisher =     {IEEE},
  title =         {Billion-scale similarity search with {GPUs}},
  volume =        {7},
  year =          {2019},
  doi =           {10.1109/TBDATA.2019.2921572},
}

@misc{tokens,
  author =        {OpenAI},
  note =          {Accessed: 15 August 2024},
  title =         {What are tokens and how to count them?},
  year =          {2023},
  url =           {https://help.openai.com/en/articles/4936856-what-are-tokens-
                  and-how-to-count-them#},
}

@inproceedings{carbonell-mmr,
  address =       {New York, NY, USA},
  author =        {Carbonell, Jaime and Goldstein, Jade},
  booktitle =     {Proceedings of the 21st Annual International ACM
                   SIGIR Conference on Research and Development in
                   Information Retrieval},
  pages =         {335–336},
  publisher =     {Association for Computing Machinery},
  series =        {SIGIR '98},
  title =         {The use of MMR, diversity-based reranking for
                   reordering documents and producing summaries},
  year =          {1998},
  doi =           {10.1145/290941.291025},
  isbn =          {1581130155},
  url =           {https://doi.org/10.1145/290941.291025},
}

@misc{tang2024strucbenchlargelanguagemodels,
  author =        {Xiangru Tang and Yiming Zong and Jason Phang and
                   Yilun Zhao and Wangchunshu Zhou and Arman Cohan and
                   Mark Gerstein},
  title =         {Struc-Bench: Are Large Language Models Really Good at
                   Generating Complex Structured Data?},
  year =          {2024},
  url =           {https://arxiv.org/abs/2309.08963},
}

@misc{json,
  author =        {OpenAI},
  note =          {Accessed: 15 August 2024},
  title =         {Introducing structured outputs in the API},
  year =          {2024},
  url =           {https://openai.com/index/introducing-structured-outputs-in-
                  the-api/#},
}

@inproceedings{cot,
  address =       {Red Hook, NY, USA},
  author =        {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and
                   Bosma, Maarten and Ichter, Brian and Xia, Fei and
                   Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
  booktitle =     {Proceedings of the 36th International Conference on
                   Neural Information Processing Systems},
  publisher =     {Curran Associates Inc.},
  series =        {NIPS '22},
  title =         {Chain-of-thought prompting elicits reasoning in large
                   language models},
  year =          {2024},
  abstract =      {We explore how generating a chain of thought—a
                   series of intermediate reasoning
                   steps—significantly improves the ability of large
                   language models to perform complex reasoning. In
                   particular, we show how such reasoning abilities
                   emerge naturally in sufficiently large language
                   models via a simple method called chain-of-thought
                   prompting, where a few chain of thought
                   demonstrations are provided as exemplars in
                   prompting.Experiments on three large language models
                   show that chain-of-thought prompting improves
                   performance on a range of arithmetic, commonsense,
                   and symbolic reasoning tasks. The empirical gains can
                   be striking. For instance, prompting a PaLM 540B with
                   just eight chain-of-thought exemplars achieves
                   state-of-the-art accuracy on the GSM8K benchmark of
                   math word problems, surpassing even finetuned GPT-3
                   with a verifier.},
  isbn =          {9781713871088},
  url =           {https://dl.acm.org/doi/10.5555/3600270.3602070},
}

@misc{menick2022teachinglanguagemodelssupport,
  author =        {Jacob Menick and Maja Trebacz and Vladimir Mikulik and
                   John Aslanides and Francis Song and Martin Chadwick and
                   Mia Glaese and Susannah Young and
                   Lucy Campbell-Gillingham and Geoffrey Irving and
                   Nat McAleese},
  title =         {Teaching language models to support answers with
                   verified quotes},
  year =          {2022},
  url =           {https://arxiv.org/abs/2203.11147},
}

@inproceedings{fewshot,
  address =       {Red Hook, NY, USA},
  author =        {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and
                   Subbiah, Melanie and Kaplan, Jared and
                   Dhariwal, Prafulla and Neelakantan, Arvind and
                   Shyam, Pranav and Sastry, Girish and Askell, Amanda and
                   Agarwal, Sandhini and Herbert-Voss, Ariel and
                   Krueger, Gretchen and Henighan, Tom and Child, Rewon and
                   Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and
                   Winter, Clemens and Hesse, Christopher and Chen, Mark and
                   Sigler, Eric and Litwin, Mateusz and Gray, Scott and
                   Chess, Benjamin and Clark, Jack and
                   Berner, Christopher and McCandlish, Sam and
                   Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  booktitle =     {Proceedings of the 34th International Conference on
                   Neural Information Processing Systems},
  publisher =     {Curran Associates Inc.},
  series =        {NIPS '20},
  title =         {Language models are few-shot learners},
  year =          {2020},
  abstract =      {We demonstrate that scaling up language models
                   greatly improves task-agnostic, few-shot performance,
                   sometimes even becoming competitive with prior
                   state-of-the-art fine-tuning approaches.
                   Specifically, we train GPT-3, an autoregressive
                   language model with 175 billion parameters, 10x more
                   than any previous non-sparse language model, and test
                   its performance in the few-shot setting. For all
                   tasks, GPT-3 is applied without any gradient updates
                   or fine-tuning, with tasks and few-shot
                   demonstrations specified purely via text interaction
                   with the model. GPT-3 achieves strong performance on
                   many NLP datasets, including translation,
                   question-answering, and cloze tasks. We also identify
                   some datasets where GPT-3's few-shot learning still
                   struggles, as well as some datasets where GPT-3 faces
                   methodological issues related to training on large
                   web corpora.},
  isbn =          {9781713829546},
  url =           {https://proceedings.neurips.cc/paper_files/paper/2020/file/
                  1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
}

@misc{golkar2023xvalcontinuousnumberencoding,
  author =        {Siavash Golkar and Mariel Pettee and
                   Michael Eickenberg and Alberto Bietti and
                   Miles Cranmer and Geraud Krawezik and
                   Francois Lanusse and Michael McCabe and Ruben Ohana and
                   Liam Parker and Bruno Régaldo-Saint Blancard and
                   Tiberiu Tesileanu and Kyunghyun Cho and Shirley Ho},
  title =         {xVal: A Continuous Number Encoding for Large Language
                   Models},
  year =          {2023},
  url =           {https://arxiv.org/abs/2310.02989},
}

@article{likert1932technique,
  author =        {Likert, Rensis},
  journal =       {Archives of Psychology},
  number =        {140},
  pages =         {55},
  title =         {A technique for the measurement of attitudes},
  volume =        {22},
  year =          {1932},
}

@article{likertstudy,
  author =        {Joshi, Ankur and Kale, Saket and Chandel, Satish and
                   Pal, Dinesh},
  journal =       {British Journal of Applied Science \& Technology},
  month =         {01},
  pages =         {396-403},
  title =         {Likert Scale: Explored and Explained},
  volume =        {7},
  year =          {2015},
  doi =           {10.9734/BJAST/2015/14975},
}

@inproceedings{NIPS1989_0336dcba,
  author =        {Bridle, John},
  booktitle =     {Advances in Neural Information Processing Systems},
  editor =        {D. Touretzky},
  pages =         {},
  publisher =     {Morgan-Kaufmann},
  title =         {Training Stochastic Model Recognition Algorithms as
                   Networks can Lead to Maximum Mutual Information
                   Estimation of Parameters},
  volume =        {2},
  year =          {1989},
  url =           {https://proceedings.neurips.cc/paper_files/paper/1989/file/
                  0336dcbab05b9d5ad24f4333c7658a0e-Paper.pdf},
}

@inproceedings{devlin-etal-2019-bert,
  address =       {Minneapolis, Minnesota},
  author =        {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and
                   Toutanova, Kristina},
  booktitle =     {Proceedings of the 2019 Conference of the North
                   {A}merican Chapter of the Association for
                   Computational Linguistics: Human Language
                   Technologies, Volume 1 (Long and Short Papers)},
  editor =        {Burstein, Jill and Doran, Christy and
                   Solorio, Thamar},
  month =         jun,
  pages =         {4171--4186},
  publisher =     {Association for Computational Linguistics},
  title =         {{BERT}: Pre-training of Deep Bidirectional
                   Transformers for Language Understanding},
  year =          {2019},
  doi =           {10.18653/v1/N19-1423},
  url =           {https://aclanthology.org/N19-1423},
}

@inproceedings{wolf-etal-2020-transformers,
  address =       {Online},
  author =        {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and
                   Chaumond, Julien and Delangue, Clement and
                   Moi, Anthony and Cistac, Pierric and Rault, Tim and
                   Louf, Remi and Funtowicz, Morgan and Davison, Joe and
                   Shleifer, Sam and von Platen, Patrick and Ma, Clara and
                   Jernite, Yacine and Plu, Julien and Xu, Canwen and
                   Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and
                   Lhoest, Quentin and Rush, Alexander},
  booktitle =     {Proceedings of the 2020 Conference on Empirical
                   Methods in Natural Language Processing: System
                   Demonstrations},
  editor =        {Liu, Qun and Schlangen, David},
  month =         oct,
  pages =         {38--45},
  publisher =     {Association for Computational Linguistics},
  title =         {Transformers: State-of-the-Art Natural Language
                   Processing},
  year =          {2020},
  doi =           {10.18653/v1/2020.emnlp-demos.6},
  url =           {https://aclanthology.org/2020.emnlp-demos.6},
}

@article{scikit-learn,
  author =        {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and
                   Michel, V. and Thirion, B. and Grisel, O. and
                   Blondel, M. and Prettenhofer, P. and Weiss, R. and
                   Dubourg, V. and Vanderplas, J. and Passos, A. and
                   Cournapeau, D. and Brucher, M. and Perrot, M. and
                   Duchesnay, E.},
  journal =       {Journal of Machine Learning Research},
  pages =         {2825--2830},
  title =         {Scikit-learn: Machine Learning in {P}ython},
  volume =        {12},
  year =          {2011},
  url =           {https://jmlr.org/papers/v12/pedregosa11a.html},
}

@misc{jaradat2024contextawaredetectioncherrypickingnews,
  author =        {Israa Jaradat and Haiqi Zhang and Chengkai Li},
  title =         {On Context-aware Detection of Cherry-picking in News
                   Reporting},
  year =          {2024},
  url =           {https://arxiv.org/abs/2401.05650},
}

@misc{dubey2024llama3herdmodels,
  author =        {Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and
                   Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and
                   Akhil Mathur and Alan Schelten and Amy Yang and
                   Angela Fan and Anirudh Goyal and Anthony Hartshorn and
                   Aobo Yang and ... and Zhiwei Zhao},
  title =         {The Llama 3 Herd of Models},
  year =          {2024},
  url =           {https://arxiv.org/abs/2407.21783},
}

@inproceedings{vllm,
  address =       {New York, NY, USA},
  author =        {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and
                   Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and
                   Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
  booktitle =     {Proceedings of the 29th Symposium on Operating
                   Systems Principles},
  pages =         {611–626},
  publisher =     {Association for Computing Machinery},
  series =        {SOSP '23},
  title =         {Efficient Memory Management for Large Language Model
                   Serving with PagedAttention},
  year =          {2023},
  abstract =      {High throughput serving of large language models
                   (LLMs) requires batching sufficiently many requests
                   at a time. However, existing systems struggle because
                   the key-value cache (KV cache) memory for each
                   request is huge and grows and shrinks dynamically.
                   When managed inefficiently, this memory can be
                   significantly wasted by fragmentation and redundant
                   duplication, limiting the batch size. To address this
                   problem, we propose PagedAttention, an attention
                   algorithm inspired by the classical virtual memory
                   and paging techniques in operating systems. On top of
                   it, we build vLLM, an LLM serving system that
                   achieves (1) near-zero waste in KV cache memory and
                   (2) flexible sharing of KV cache within and across
                   requests to further reduce memory usage. Our
                   evaluations show that vLLM improves the throughput of
                   popular LLMs by 2--4\texttimes{} with the same level
                   of latency compared to the state-of-the-art systems,
                   such as FasterTransformer and Orca. The improvement
                   is more pronounced with longer sequences, larger
                   models, and more complex decoding algorithms. vLLM's
                   source code is publicly available at
                   https://github.com/vllm-project/vllm.},
  doi =           {10.1145/3600006.3613165},
  isbn =          {9798400702297},
  url =           {https://doi.org/10.1145/3600006.3613165},
}

@inproceedings{schlichtkrull-etal-2024-automated,
  address =       {Miami, Florida, USA},
  author =        {Schlichtkrull, Michael and Chen, Yulong and
                   Whitehouse, Chenxi and Deng, Zhenyun and
                   Akhtar, Mubashara and Aly, Rami and Guo, Zhijiang and
                   Christodoulopoulos, Christos and Cocarascu, Oana and
                   Mittal, Arpit and Thorne, James and Vlachos, Andreas},
  booktitle =     {Proceedings of the Seventh Fact Extraction and
                   VERification Workshop (FEVER)},
  editor =        {Schlichtkrull, Michael and Chen, Yulong and
                   Whitehouse, Chenxi and Deng, Zhenyun and
                   Akhtar, Mubashara and Aly, Rami and Guo, Zhijiang and
                   Christodoulopoulos, Christos and Cocarascu, Oana and
                   Mittal, Arpit and Thorne, James and Vlachos, Andreas},
  month =         nov,
  pages =         {1--26},
  publisher =     {Association for Computational Linguistics},
  title =         {The Automated Verification of Textual Claims
                   ({AV}eri{T}e{C}) Shared Task},
  year =          {2024},
  doi =           {10.18653/v1/2024.fever-1.1},
  url =           {https://aclanthology.org/2024.fever-1.1/},
}

@inproceedings{rothermel-etal-2024-infact,
  address =       {Miami, Florida, USA},
  author =        {Rothermel, Mark and Braun, Tobias and
                   Rohrbach, Marcus and Rohrbach, Anna},
  booktitle =     {Proceedings of the Seventh Fact Extraction and
                   VERification Workshop (FEVER)},
  editor =        {Schlichtkrull, Michael and Chen, Yulong and
                   Whitehouse, Chenxi and Deng, Zhenyun and
                   Akhtar, Mubashara and Aly, Rami and Guo, Zhijiang and
                   Christodoulopoulos, Christos and Cocarascu, Oana and
                   Mittal, Arpit and Thorne, James and Vlachos, Andreas},
  month =         nov,
  pages =         {108--112},
  publisher =     {Association for Computational Linguistics},
  title =         {{I}n{F}act: A Strong Baseline for Automated
                   Fact-Checking},
  year =          {2024},
  doi =           {10.18653/v1/2024.fever-1.12},
  url =           {https://aclanthology.org/2024.fever-1.12/},
}

@inproceedings{ullrich-etal-2024-aic,
  address =       {Miami, Florida, USA},
  author =        {Ullrich, Herbert and
                   Mlyn{\'a}{\v{r}}, Tom{\'a}{\v{s}} and Drchal, Jan},
  booktitle =     {Proceedings of the Seventh Fact Extraction and
                   VERification Workshop (FEVER)},
  editor =        {Schlichtkrull, Michael and Chen, Yulong and
                   Whitehouse, Chenxi and Deng, Zhenyun and
                   Akhtar, Mubashara and Aly, Rami and Guo, Zhijiang and
                   Christodoulopoulos, Christos and Cocarascu, Oana and
                   Mittal, Arpit and Thorne, James and Vlachos, Andreas},
  month =         nov,
  pages =         {137--150},
  publisher =     {Association for Computational Linguistics},
  title =         {{AIC} {CTU} system at {AV}eri{T}e{C}: Re-framing
                   automated fact-checking as a simple {RAG} task},
  year =          {2024},
  doi =           {10.18653/v1/2024.fever-1.16},
  url =           {https://aclanthology.org/2024.fever-1.16/},
}

@inproceedings{yoon-etal-2024-hero,
  address =       {Miami, Florida, USA},
  author =        {Yoon, Yejun and Jung, Jaeyoon and Yoon, Seunghyun and
                   Park, Kunwoo},
  booktitle =     {Proceedings of the Seventh Fact Extraction and
                   VERification Workshop (FEVER)},
  editor =        {Schlichtkrull, Michael and Chen, Yulong and
                   Whitehouse, Chenxi and Deng, Zhenyun and
                   Akhtar, Mubashara and Aly, Rami and Guo, Zhijiang and
                   Christodoulopoulos, Christos and Cocarascu, Oana and
                   Mittal, Arpit and Thorne, James and Vlachos, Andreas},
  month =         nov,
  pages =         {130--136},
  publisher =     {Association for Computational Linguistics},
  title =         {{H}er{O} at {AV}eri{T}e{C}: The Herd of Open Large
                   Language Models for Verifying Real-World Claims},
  year =          {2024},
  doi =           {10.18653/v1/2024.fever-1.15},
  url =           {https://aclanthology.org/2024.fever-1.15/},
}

@misc{yang2025qwen3technicalreport,
  author =        {An Yang and Anfeng Li and Baosong Yang and
                   Beichen Zhang and Binyuan Hui and Bo Zheng and
                   Bowen Yu and Chang Gao and Chengen Huang and
                   Chenxu Lv and Chujie Zheng and Dayiheng Liu and
                   Fan Zhou and Fei Huang and Feng Hu ... Zhipeng Zhou and
                   Zihan Qiu},
  title =         {Qwen3 Technical Report},
  year =          {2025},
  url =           {https://arxiv.org/abs/2505.09388},
}

@misc{akhtar2024ev2r,
  author =        {Mubashara Akhtar and Michael Schlichtkrull and
                   Andreas Vlachos},
  title =         {Ev2R: Evaluating Evidence Retrieval in Automated
                   Fact-Checking},
  year =          {2024},
  url =           {https://arxiv.org/abs/2411.05375},
}

@inproceedings{malon-2024-multi,
  address =       {Miami, Florida, USA},
  author =        {Malon, Christopher},
  booktitle =     {Proceedings of the Seventh Fact Extraction and
                   VERification Workshop (FEVER)},
  editor =        {Schlichtkrull, Michael and Chen, Yulong and
                   Whitehouse, Chenxi and Deng, Zhenyun and
                   Akhtar, Mubashara and Aly, Rami and Guo, Zhijiang and
                   Christodoulopoulos, Christos and Cocarascu, Oana and
                   Mittal, Arpit and Thorne, James and Vlachos, Andreas},
  month =         nov,
  pages =         {27--36},
  publisher =     {Association for Computational Linguistics},
  title =         {Multi-hop Evidence Pursuit Meets the Web: Team Papelo
                   at {FEVER} 2024},
  year =          {2024},
  doi =           {10.18653/v1/2024.fever-1.2},
  url =           {https://aclanthology.org/2024.fever-1.2/},
}

@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
  author =        {DeepSeek-AI and Daya Guo and Dejian Yang and
                   Haowei Zhang and Junxiao Song and Ruoyu Zhang and
                   Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and
                   Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and
                   Z. F. Wu and ... and Zhen Zhang},
  title =         {DeepSeek-R1: Incentivizing Reasoning Capability in
                   LLMs via Reinforcement Learning},
  year =          {2025},
  url =           {https://arxiv.org/abs/2501.12948},
}

@article{barbaresi-2020-htmldate,
  title = {{htmldate: A Python package to extract publication dates from web pages}},
  author = {Barbaresi, Adrien},
  journal = {Journal of Open Source Software},
  volume = 5,
  number = 51,
  pages = 2439,
  url = {https://doi.org/10.21105/joss.02439},
  publisher = {The Open Journal},
  year = 2020,
}

@misc{cao2025averimatecdatasetautomaticverification,
      title={AVerImaTeC: A Dataset for Automatic Verification of Image-Text Claims with Evidence from the Web},
      author={Rui Cao and Zifeng Ding and Zhijiang Guo and Michael Schlichtkrull and Andreas Vlachos},
      year={2025},
      eprint={2505.17978},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.17978},
}

@inproceedings{akhtar-etal-2025-2nd,
    title = {The 2nd Shared Task on Automated Fact Verification for Climate Science Claims},
    author = {Akhtar, Mubashara and Schlichtkrull, Michael and Vlachos, Andreas},
    booktitle = {Proceedings of the 2nd Workshop on Automated Fact Verification},
    year = {2025},
}

@inproceedings{glockner-etal-2022-missing,
    title = {Missing Counter-Evidence Renders {NLI} Data Inadequate for Fact Verification},
    author = {Glockner, Max and Hou, Yufang and Gurevych, Iryna},
    booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
    year = {2022},
}

@inproceedings{ullrich-drchal-2025-aic,
    title = {{AIC CTU} System for the 2nd {AVeriTeC} Shared Task},
    author = {Ullrich, Herbert and Drchal, Jan},
    booktitle = {Proceedings of the 2nd Workshop on Automated Fact Verification},
    year = {2025},
}

@proceedings{fever-2022-fact,
  title     = {Proceedings of the Fifth Fact Extraction and VERification Workshop (FEVER)},
  editor    = {Aly, Rami and Christodoulopoulos, Christos and Cocarascu, Oana and Guo, Zhijiang and Mittal, Arpit and Schlichtkrull, Michael and Thorne, James and Vlachos, Andreas},
  month     = may,
  year      = {2022},
  address   = {Dublin, Ireland},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.fever-1.0}
}

@inproceedings{thorne-vlachos-2021-evidence,
  title     = {Evidence-based Factual Error Correction},
  author    = {Thorne, James and Vlachos, Andreas},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-long.256},
  doi       = {10.18653/v1/2021.acl-long.256},
  pages     = {3298--3309}
}

@misc{barroncedeno2020overview,
  title         = {Overview of CheckThat! 2020: Automatic Identification and Verification of Claims in Social Media},
  author        = {Alberto Barr{\'o}n-Cede{\~{n}}o and Tamer Elsayed and Preslav Nakov and Giovanni Da San Martino and Maram Hasanain and Reem Suwaileh and Fatima Haouari and Nikolay Babulkov and Bayan Hamdan and Alex Nikolov and Shaden Shaar and Zien Sheikh Ali},
  year          = {2020},
  eprint        = {2007.07997},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{sheikhi-etal-2023-automated,
  title     = {Automated Claim Detection for Fact-checking: A Case Study using {N}orwegian Pre-trained Language Models},
  author    = {Sheikhi, Ghazaal and Touileb, Samia and Khan, Sohail},
  booktitle = {Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)},
  month     = may,
  year      = {2023},
  address   = {T{\'o}rshavn, Faroe Islands},
  publisher = {University of Tartu Library},
  url       = {https://aclanthology.org/2023.nodalida-1.1},
  pages     = {1--9}
}

@inproceedings{deng-etal-2024-document,
  title     = {Document-level Claim Extraction and Decontextualisation for Fact-Checking},
  author    = {Deng, Zhenyun and Schlichtkrull, Michael and Vlachos, Andreas},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = aug,
  year      = {2024},
  address   = {Bangkok, Thailand},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.acl-long.645},
  doi       = {10.18653/v1/2024.acl-long.645},
  pages     = {11943--11954}
}

@inproceedings{pan-etal-2021-zero,
  title     = {Zero-shot Fact Verification by Claim Generation},
  author    = {Pan, Liangming and Chen, Wenhu and Xiong, Wenhan and Kan, Min-Yen and Wang, William Yang},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-short.61},
  doi       = {10.18653/v1/2021.acl-short.61},
  pages     = {476--483}
}

@inproceedings{mao-etal-2022-citesum,
  title     = {{C}ite{S}um: Citation Text-guided Scientific Extreme Summarization and Domain Adaptation with Limited Supervision},
  author    = {Mao, Yuning and Zhong, Ming and Han, Jiawei},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.emnlp-main.750},
  doi       = {10.18653/v1/2022.emnlp-main.750},
  pages     = {10922--10935}
}

@inproceedings{wright-etal-2022-generating,
  title     = {Generating Scientific Claims for Zero-Shot Scientific Fact Checking},
  author    = {Wright, Dustin and Wadden, David and Lo, Kyle and Kuehl, Bailey and Cohan, Arman and Augenstein, Isabelle and Wang, Lucy Lu},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = may,
  year      = {2022},
  address   = {Dublin, Ireland},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.acl-long.175},
  doi       = {10.18653/v1/2022.acl-long.175},
  pages     = {2448--2460}
}

@InBook{10.1007/978-3-642-38288-8_33,
  author    = {Kuhn, Tobias and Barbano, Paolo Emilio and Nagy, Mate Levente and Krauthammer, Michael},
  title     = {Broadening the Scope of Nanopublications},
  booktitle = {The Semantic Web: Semantics and Big Data},
  year      = {2013},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {487--501},
  doi       = {10.1007/978-3-642-38288-8_33},
  isbn      = {978-3-642-38288-8}
}

@InProceedings{10.1007/978-3-031-28241-6_59,
  author    = {Barr{\'o}n-Cede{\~{n}}o, Alberto and Alam, Firoj and Caselli, Tommaso and Da San Martino, Giovanni and Elsayed, Tamer and Galassi, Andrea and Haouari, Fatima and Ruggeri, Federico and Struss, Julia Maria and Nandi, Rabindra Nath and Cheema, Gullal S. and Azizov, Dilshod and Nakov, Preslav},
  title     = {The CLEF-2023 CheckThat! Lab: Checkworthiness, Subjectivity, Political Bias, Factuality, and Authority},
  booktitle = {Advances in Information Retrieval},
  year      = {2023},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {506--517},
  isbn      = {978-3-031-28241-6}
}

@misc{sutskever-2014,
  author    = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
  title     = {Sequence to Sequence Learning with Neural Networks},
  year      = {2014},
  eprint    = {1409.3215},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{NEURIPS2020_1457c0d6,
  author    = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {1877--1901},
  publisher = {Curran Associates, Inc.},
  title     = {Language Models are Few-Shot Learners},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
  volume    = {33},
  year      = {2020}
}

@misc{openai2023gpt4,
  title         = {{GPT}-4 Technical Report},
  author        = {OpenAI},
  year          = {2023},
  eprint        = {2303.08774},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{jiang2023mistral,
  title         = {Mistral 7B},
  author        = {Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and L{\'e}lio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timoth{\'e}e Lacroix and William El Sayed},
  year          = {2023},
  eprint        = {2310.06825},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{2020t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@inproceedings{hasan-etal-2021-xl,
  title     = {{XL}-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages},
  author    = {Hasan, Tahmid and Bhattacharjee, Abhik and Islam, Md. Saiful and Mubasshir, Kazi and Li, Yuan-Fang and Kang, Yong-Bin and Rahman, M. Sohel and Shahriyar, Rifat},
  booktitle = {Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.findings-acl.413},
  doi       = {10.18653/v1/2021.findings-acl.413},
  pages     = {4693--4703}
}

@article{vijaykumar_beam,
  title   = {Diverse Beam Search for Improved Description of Complex Scenes},
  volume  = {32},
  url     = {https://ojs.aaai.org/index.php/AAAI/article/view/12340},
  doi     = {10.1609/aaai.v32i1.12340},
  number  = {1},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author  = {Vijayakumar, Ashwin and Cogswell, Michael and Selvaraju, Ramprasaath and Sun, Qing and Lee, Stefan and Crandall, David and Batra, Dhruv},
  year    = {2018},
  month   = {Apr.}
}

@inproceedings{sadvilkar-neumann-2020-pysbd,
  title     = {{P}y{SBD}: Pragmatic Sentence Boundary Disambiguation},
  author    = {Sadvilkar, Nipun and Neumann, Mark},
  booktitle = {Proceedings of Second Workshop for NLP Open Source Software (NLP-OSS)},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.nlposs-1.15},
  doi       = {10.18653/v1/2020.nlposs-1.15},
  pages     = {110--114}
}

@inproceedings{huguet-cabot-navigli-2021-rebel-relation,
  title     = {{REBEL}: Relation Extraction By End-to-end Language generation},
  author    = {Huguet Cabot, Pere-Llu{\'\i}s and Navigli, Roberto},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2021},
  month     = nov,
  year      = {2021},
  address   = {Punta Cana, Dominican Republic},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.findings-emnlp.204},
  doi       = {10.18653/v1/2021.findings-emnlp.204},
  pages     = {2370--2381}
}

@inproceedings{yamada-etal-2020-luke,
  title     = {{LUKE}: Deep Contextualized Entity Representations with Entity-aware Self-attention},
  author    = {Yamada, Ikuya and Asai, Akari and Shindo, Hiroyuki and Takeda, Hideaki and Matsumoto, Yuji},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.emnlp-main.523},
  doi       = {10.18653/v1/2020.emnlp-main.523},
  pages     = {6442--6454}
}

@inproceedings{kann-etal-2018-sentence,
  title     = {Sentence-Level Fluency Evaluation: References Help, But Can Be Spared!},
  author    = {Kann, Katharina and Rothe, Sascha and Filippova, Katja},
  booktitle = {Proceedings of the 22nd Conference on Computational Natural Language Learning},
  month     = oct,
  year      = {2018},
  address   = {Brussels, Belgium},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/K18-1031},
  doi       = {10.18653/v1/K18-1031},
  pages     = {313--323}
}

@inproceedings{raheja-etal-2023-coedit,
  title     = {{C}o{E}d{IT}: Text Editing by Task-Specific Instruction Tuning},
  author    = {Raheja, Vipul and Kumar, Dhruv and Koo, Ryan and Kang, Dongyeop},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2023},
  month     = dec,
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.findings-emnlp.350},
  doi       = {10.18653/v1/2023.findings-emnlp.350},
  pages     = {5274--5291}
}

@inproceedings{islam-magnani-2021-end,
  title     = {Is this the end of the gold standard? {A} straightforward reference-less grammatical error correction metric},
  author    = {Islam, Md Asadul and Magnani, Enrico},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.emnlp-main.239},
  doi       = {10.18653/v1/2021.emnlp-main.239},
  pages     = {3009--3015}
}

@inproceedings{heilman-etal-2014-predicting,
  title     = {Predicting Grammaticality on an Ordinal Scale},
  author    = {Heilman, Michael and Cahill, Aoife and Madnani, Nitin and Lopez, Melissa and Mulholland, Matthew and Tetreault, Joel},
  booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  month     = jun,
  year      = {2014},
  address   = {Baltimore, Maryland},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P14-2029},
  doi       = {10.3115/v1/P14-2029},
  pages     = {174--180}
}

@inproceedings{fu-etal-2024-gptscore,
  title     = {{GPTS}core: Evaluate as You Desire},
  author    = {Fu, Jinlan and Ng, See-Kiong and Jiang, Zhengbao and Liu, Pengfei},
  booktitle = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  month     = jun,
  year      = {2024},
  address   = {Mexico City, Mexico},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.naacl-long.365},
  doi       = {10.18653/v1/2024.naacl-long.365},
  pages     = {6556--6576}
}

@inproceedings{zha-etal-2023-alignscore,
  title     = {{A}lign{S}core: Evaluating Factual Consistency with A Unified Alignment Function},
  author    = {Zha, Yuheng and Yang, Yichi and Li, Ruichen and Hu, Zhiting},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.634},
  doi       = {10.18653/v1/2023.acl-long.634},
  pages     = {11328--11348}
}

@inproceedings{reimers-gurevych-2019-sentence,
  title     = {Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks},
  author    = {Reimers, Nils and Gurevych, Iryna},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  month     = nov,
  year      = {2019},
  address   = {Hong Kong, China},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D19-1410},
  doi       = {10.18653/v1/D19-1410},
  pages     = {3982--3992}
}

@misc{he2021deberta,
  title         = {{DEB}e{RTA}: Decoding-Enhanced {BERT} with Disentangled Attention},
  author        = {Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
  year          = {2021},
  eprint        = {2006.03654},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{he2021debertav3,
  title         = {{DEB}e{RTA}v3: Improving {DEB}e{RTA} using {ELECTRA}-Style Pre-Training with Gradient-Disentangled Embedding Sharing},
  author        = {Pengcheng He and Jianfeng Gao and Weizhu Chen},
  year          = {2021},
  eprint        = {2111.09543},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{dammu-etal-2024-claimver,
  title     = {{C}laim{V}er: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs},
  author    = {Dammu, Preetam Prabhu Srikar and Naidu, Himanshu and Dewan, Mouly and Kim, YoungMin and Roosta, Tanya and Chadha, Aman and Shah, Chirag},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2024},
  month     = nov,
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.findings-emnlp.795},
  doi       = {10.18653/v1/2024.findings-emnlp.795},
  pages     = {13613--13627}
}

@article{krippendorff2011computing,
  title   = {Computing {K}rippendorff's alpha-reliability},
  author  = {Krippendorff, Klaus},
  year    = {2011},
  journal = {Departmental Papers (ASC)},
  url     = {https://repository.upenn.edu/asc_papers/43}
}

@book{gwet2010handbook,
  title     = {Handbook of Inter-rater Reliability: The Definitive Guide to Measuring the Extent of Agreement Among Raters},
  author    = {Gwet, Kilem L.},
  year      = {2010},
  publisher = {Advanced Analytics, LLC}
}

@InBook{Artstein2017,
  author    = {Artstein, Ron},
  title     = {Inter-annotator Agreement},
  booktitle = {Handbook of Linguistic Annotation},
  year      = {2017},
  publisher = {Springer Netherlands},
  address   = {Dordrecht},
  pages     = {297--313},
  doi       = {10.1007/978-94-024-0881-2_11},
  isbn      = {978-94-024-0881-2}
}

@article{rufibach2010use,
  author  = {Rufibach, Kaspar},
  title   = {Use of {B}rier score to assess binary predictions},
  journal = {Journal of Clinical Epidemiology},
  year    = {2010},
  volume  = {63},
  number  = {8},
  pages   = {938--939},
  doi     = {10.1016/j.jclinepi.2009.11.009}
}

@phdthesis{fernandes,
  author = {Fernandes, Jose},
  year   = {2011},
  month  = {05},
  title  = {Data analysis advances in marine science for fisheries management: Supervised classification applications}
}

@misc{drchal2023pipeline,
  author    = {Drchal, Jan and Ullrich, Herbert and Mlyn{\'a}{\v{r}}, Tom{\'a}{\v{s}} and Moravec, V{\'a}clav},
  title     = {Pipeline and dataset generation for automated fact-checking in almost any language},
  journal   = {Neural Computing and Applications},
  year      = {2024},
  volume    = {36},
  number    = {30},
  pages     = {19023--19054},
  doi       = {10.1007/s00521-024-10113-5},
  url       = {https://doi.org/10.1007/s00521-024-10113-5}
}

